{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizadores en Pytorch\n",
    "\n",
    "En este  notebook vamos a prestar una especial atención a los optimizadores en Pytorch. \n",
    "\n",
    "Los optimizadores se encuentran agrupados dentro del paquete torch.optim. Su rol dentro del proceso de aprendizaje es integrarse con el mecanismo de autograd de los tensores y proporcionar una implementación de la pasada *backward*. Para ello, tienen que obtener información de cómo de lejos está el modelo de la salida deseada para realizar un cálculo de los gradientes a aplicar sobre los parámetros del modelo. Las funciones de pérdida se tratan de forma separada en otro notebook.\n",
    "\n",
    "Algunas características comunes a los optimizadores de Pytorch son:\n",
    "\n",
    "- Mantienen el estado actual y actualizan los parámetros usando un cálculo de sus gradientes\n",
    "- Tienen una interfaz común que facilita \n",
    "    - Que sean fácilmente intercambiables\n",
    "    - Que se pueden implementar optimizadores ad-hoc\n",
    "- Reciben un iterables con los parámetros aprendibles del modelo\n",
    "    - También reciben otros parámetros, llamados hiperparámetros del optimizador, que permite su configuración (ejs. learning rate, momentum)\n",
    "\n",
    "Métodos principales:\n",
    "\n",
    "- *backward()*: Calcula los gradientes. Se aplica a la función de pérdida, no al optimizador.\n",
    "- *zero_grad()*: Pone a 0 los gradientes del optimizador\n",
    "- *step()*: Aplica los gradientes calculados por *backward()* a los parámetros del modelo\n",
    "\n",
    "La clase base del optimizador es optim.Optimizer y recibe como parámetros:\n",
    "- Un interable que contiene los parámetros a optimizar\n",
    "- Un diccionario con los hiperparámetros del optimizador (lr, momentum, etc...)\n",
    "\n",
    "A continuación iremos viendo ejemplos ilustrativos del uso de los optimizadores más comunes: SGD, RMSProp, Adagrad, Adam, Adadelta.\n",
    "\n",
    "Empecemos por Stochastic Gradiente Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Época 1, Pérdida: 1.7768517238709627\n",
      "Época 2, Pérdida: 1.3932885832493873\n",
      "Época 3, Pérdida: 1.2550515693319424\n",
      "Época 4, Pérdida: 1.158853273943562\n",
      "Época 5, Pérdida: 1.0884042653586248\n",
      "Época 6, Pérdida: 1.0276772107004815\n",
      "Época 7, Pérdida: 0.973789001745946\n",
      "Época 8, Pérdida: 0.9205946205445873\n",
      "Época 9, Pérdida: 0.8784698215134613\n",
      "Época 10, Pérdida: 0.8438497624738747\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Definimos las transformaciones para los conjuntos de datos\n",
    "transform = transforms.Compose([\n",
    "    # Transformamos las imágenes a tensores\n",
    "    transforms.ToTensor(),\n",
    "    # Normalizamos los tensores con media 0.5 y desviación estándar 0.5\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  \n",
    "])\n",
    "\n",
    "# Cargamos los conjuntos de datos CIFAR-10\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Definimos una red convolucional simple\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  # 3 canales de entrada para RGB, 6 de salida, kernel de 5x5\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)  # 10 clases de salida para CIFAR-10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# Especificamos la función de pérdida y el optimizador\n",
    "# En CrossEntropyLoss, el mejor valor de la función de pérdida es 0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# SGD: Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, foreach=False, nesterov=False)\n",
    "\n",
    "# Finalmente, entrenamos el modelo\n",
    "# Durante 10 épocas\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    # Para cada lote de datos\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Obtenemos las entradas y las etiquetas del lote del conjunto de entrenamiento\n",
    "        inputs, labels = data\n",
    "        # Reiniciamos los gradientes\n",
    "        optimizer.zero_grad()\n",
    "        # Hacemos una pasada hacia adelante\n",
    "        outputs = model(inputs)\n",
    "        # Calculamos la pérdida\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Hacemos una pasada hacia atrás\n",
    "        loss.backward()\n",
    "        # Actualizamos los parámetros\n",
    "        optimizer.step()\n",
    "        # Imprimimos estadísticas\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Época {epoch+1}, Pérdida: {running_loss/len(trainloader)}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior, podemos hacer distintas ejecuciones cambiando los valores de los parámetros de la celda de construcción del optimizador:\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, foreach=False, nesterov=False)\n",
    "\n",
    "A continuación, vamos a hacer lo mismo, pero cambiando el optimizador SGD, por Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "# Definimos las transformaciones para los conjuntos de datos\n",
    "transform = transforms.Compose([\n",
    "    # Transformamos las imágenes a tensores\n",
    "    transforms.ToTensor(),\n",
    "    # Normalizamos los tensores con media 0.5 y desviación estándar 0.5\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  \n",
    "])\n",
    "\n",
    "# Cargamos los conjuntos de datos CIFAR-10\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Definimos una red convolucional simple\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  # 3 canales de entrada para RGB, 6 de salida, kernel de 5x5\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)  # 10 clases de salida para CIFAR-10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# Especificamos la función de pérdida y el optimizador\n",
    "# En CrossEntropyLoss, el mejor valor de la función de pérdida es 0\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adagrad\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "\n",
    "# Finalmente, entrenamos el modelo\n",
    "# Durante 10 épocas\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    # Para cada lote de datos\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Obtenemos las entradas y las etiquetas del lote del conjunto de entrenamiento\n",
    "        inputs, labels = data\n",
    "        # Reiniciamos los gradientes\n",
    "        optimizer.zero_grad()\n",
    "        # Hacemos una pasada hacia adelante\n",
    "        outputs = model(inputs)\n",
    "        # Calculamos la pérdida\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Hacemos una pasada hacia atrás\n",
    "        loss.backward()\n",
    "        # Actualizamos los parámetros\n",
    "        optimizer.step()\n",
    "        # Imprimimos estadísticas\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Época {epoch+1}, Pérdida: {running_loss/len(trainloader)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos cuál es la diferencia en tiempo de ejecución, y en el valor de la función de pérdida alcanzado después de las 10 epochs.\n",
    "\n",
    "Podemos hacer cambios en los parámetros del constructor del optimizador:\n",
    "\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
    "\n",
    "y ver qué influencia tienen estos cambios en el tiempo de ejecución y en la precisión final alcanzada tras las 10 epochs. \n",
    "\n",
    "Ahora, vamos a probar sucesivamente los optimizadores RMSProp y Adam con el mismo ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1, Pérdida: 4.350290635662615\n",
      "Época 2, Pérdida: 1.7119790146417935\n",
      "Época 3, Pérdida: 1.6144331010711162\n",
      "Época 4, Pérdida: 1.5453425831806935\n",
      "Época 5, Pérdida: 1.4896152059135535\n",
      "Época 6, Pérdida: 1.4534931237740285\n",
      "Época 7, Pérdida: 1.4303689374185888\n",
      "Época 8, Pérdida: 1.4178671717186413\n",
      "Época 9, Pérdida: 1.3916981996935043\n",
      "Época 10, Pérdida: 1.3754545522620305\n"
     ]
    }
   ],
   "source": [
    "# RMSprop\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "# Finalmente, entrenamos el modelo\n",
    "# Durante 10 épocas\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    # Para cada lote de datos\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Obtenemos las entradas y las etiquetas del lote del conjunto de entrenamiento\n",
    "        inputs, labels = data\n",
    "        # Reiniciamos los gradientes\n",
    "        optimizer.zero_grad()\n",
    "        # Hacemos una pasada hacia adelante\n",
    "        outputs = model(inputs)\n",
    "        # Calculamos la pérdida\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Hacemos una pasada hacia atrás\n",
    "        loss.backward()\n",
    "        # Actualizamos los parámetros\n",
    "        optimizer.step()\n",
    "        # Imprimimos estadísticas\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Época {epoch+1}, Pérdida: {running_loss/len(trainloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1, Pérdida: 1.1669400319876269\n",
      "Época 2, Pérdida: 1.108642712654665\n",
      "Época 3, Pérdida: 1.0825879107350889\n",
      "Época 4, Pérdida: 1.058956936039888\n",
      "Época 5, Pérdida: 1.0396547212320215\n",
      "Época 6, Pérdida: 1.022629377329746\n",
      "Época 7, Pérdida: 1.0058141559591074\n",
      "Época 8, Pérdida: 0.9915005305539006\n",
      "Época 9, Pérdida: 0.9772829066609483\n",
      "Época 10, Pérdida: 0.964328788278048\n"
     ]
    }
   ],
   "source": [
    "# Adam\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "# Finalmente, entrenamos el modelo\n",
    "# Durante 10 épocas\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    # Para cada lote de datos\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Obtenemos las entradas y las etiquetas del lote del conjunto de entrenamiento\n",
    "        inputs, labels = data\n",
    "        # Reiniciamos los gradientes\n",
    "        optimizer.zero_grad()\n",
    "        # Hacemos una pasada hacia adelante\n",
    "        outputs = model(inputs)\n",
    "        # Calculamos la pérdida\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Hacemos una pasada hacia atrás\n",
    "        loss.backward()\n",
    "        # Actualizamos los parámetros\n",
    "        optimizer.step()\n",
    "        # Imprimimos estadísticas\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Época {epoch+1}, Pérdida: {running_loss/len(trainloader)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los dos casos anteriores, podemos hacer las mismas pruebas de variación de hiperparámetros que hicimos con los otros dos optimizadores, y observar el efecto que tienen. \n",
    "\n",
    "## Ajuste del Learning Rate\n",
    "\n",
    "En los ejemplos anteriores, hemos fijado el *Learning Rate* (*lr*) en el momento de creación del optimizador, como un parámetro del mismo. Es cierto, que algunos de esos algoritmos van adaptando el *lr* de forma dinámica, en función de datos estadísticos del entrenamiento, pero también existe otro mecanismo que permite adaptar el learning rate dinámicamente, desde fuera del optimizador. Ambos mecanismos se pueden usar de forma conjunta, pero esto podría producir efectos inesperados. Lo habitual, sería utilizar estos mecanismo adaptación en conjunción con optimizadores como SGD que no incorporan un mecanismo de este tipo.\n",
    "\n",
    "Exploremos su uso, recuperando la versión SGD de nuestro ejemplo. En ella, usamos uno de estos planificadores (StepLR). A modo informativo, imprimimos el *lr* al final de cada epoch, para poder observar las actualizaciones realizadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1, Pérdida: 1.0616193891638686\n",
      "Época 1, Pérdida: 1.0616193891638686, Tasa de aprendizaje: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegoandrade/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:389: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 2, Pérdida: 1.060785426584351\n",
      "Época 2, Pérdida: 1.060785426584351, Tasa de aprendizaje: 0.0001\n",
      "Época 3, Pérdida: 0.9327894711433469\n",
      "Época 3, Pérdida: 0.9327894711433469, Tasa de aprendizaje: 0.001\n",
      "Época 4, Pérdida: 0.9176132407639642\n",
      "Época 4, Pérdida: 0.9176132407639642, Tasa de aprendizaje: 1e-05\n",
      "Época 5, Pérdida: 0.9062913428334629\n",
      "Época 5, Pérdida: 0.9062913428334629, Tasa de aprendizaje: 0.0001\n",
      "Época 6, Pérdida: 0.9046423651678178\n",
      "Época 6, Pérdida: 0.9046423651678178, Tasa de aprendizaje: 1.0000000000000002e-06\n",
      "Época 7, Pérdida: 0.9033941689049801\n",
      "Época 7, Pérdida: 0.9033941689049801, Tasa de aprendizaje: 1e-05\n",
      "Época 8, Pérdida: 0.9037410588673008\n",
      "Época 8, Pérdida: 0.9037410588673008, Tasa de aprendizaje: 1.0000000000000002e-07\n",
      "Época 9, Pérdida: 0.9031907985429934\n",
      "Época 9, Pérdida: 0.9031907985429934, Tasa de aprendizaje: 1.0000000000000002e-06\n",
      "Época 10, Pérdida: 0.902754614496475\n",
      "Época 10, Pérdida: 0.902754614496475, Tasa de aprendizaje: 1.0000000000000004e-08\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.optim import lr_scheduler\n",
    "# SGD: Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, foreach=False, nesterov=False)\n",
    "# Creamos un programador de tasa de aprendizaje\n",
    "# Cada 7 épocas, la tasa de aprendizaje se multiplicará por 0.1\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "# Finalmente, entrenamos el modelo\n",
    "# Durante 10 épocas\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    # Para cada lote de datos\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Obtenemos las entradas y las etiquetas del lote del conjunto de entrenamiento\n",
    "        inputs, labels = data\n",
    "        # Reiniciamos los gradientes\n",
    "        optimizer.zero_grad()\n",
    "        # Hacemos una pasada hacia adelante\n",
    "        outputs = model(inputs)\n",
    "        # Calculamos la pérdida\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Hacemos una pasada hacia atrás\n",
    "        loss.backward()\n",
    "        # Actualizamos los parámetros usando el step del optimizador\n",
    "        optimizer.step()\n",
    "        # Imprimimos estadísticas\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Época {epoch+1}, Pérdida: {running_loss/len(trainloader)}')\n",
    "    # Actualizamos el lr usando el step del planifcador de lr\n",
    "    scheduler.step()\n",
    "    print(f'Época {epoch+1}, Pérdida: {running_loss/len(trainloader)}, Tasa de aprendizaje: {scheduler.get_lr()[0]}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos ahora, con un planificador más sofisticado: *CosineAnnealingLR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1, Pérdida: 2.297729554688534\n",
      "Época 1, Pérdida: 2.297729554688534, Tasa de aprendizaje: 0.025\n",
      "Época 2, Pérdida: 2.30465518818487\n",
      "Época 2, Pérdida: 2.30465518818487, Tasa de aprendizaje: 0.0\n",
      "Época 3, Pérdida: 2.3037346436849337\n",
      "Época 3, Pérdida: 2.3037346436849337, Tasa de aprendizaje: 0.09999999999999999\n",
      "Época 4, Pérdida: 2.30509191644771\n",
      "Época 4, Pérdida: 2.30509191644771, Tasa de aprendizaje: 0.2000000000000001\n",
      "Época 5, Pérdida: 2.3061529745531204\n",
      "Época 5, Pérdida: 2.3061529745531204, Tasa de aprendizaje: 0.02500000000000002\n",
      "Época 6, Pérdida: 2.3040546550775125\n",
      "Época 6, Pérdida: 2.3040546550775125, Tasa de aprendizaje: 0.0\n",
      "Época 7, Pérdida: 2.3047193660760477\n",
      "Época 7, Pérdida: 2.3047193660760477, Tasa de aprendizaje: 0.09999999999999999\n",
      "Época 8, Pérdida: 2.3044501354017526\n",
      "Época 8, Pérdida: 2.3044501354017526, Tasa de aprendizaje: 0.20000000000000015\n",
      "Época 9, Pérdida: 2.3063098192214966\n",
      "Época 9, Pérdida: 2.3063098192214966, Tasa de aprendizaje: 0.02500000000000003\n",
      "Época 10, Pérdida: 2.3045073217138303\n",
      "Época 10, Pérdida: 2.3045073217138303, Tasa de aprendizaje: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.optim import lr_scheduler\n",
    "# SGD: Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, foreach=False, nesterov=False)\n",
    "# Creamos un programador de tasa de aprendizaje\n",
    "# Cada 7 épocas, la tasa de aprendizaje se multiplicará por 0.1\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=2, eta_min=0)\n",
    "\n",
    "# Finalmente, entrenamos el modelo\n",
    "# Durante 10 épocas\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    # Para cada lote de datos\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Obtenemos las entradas y las etiquetas del lote del conjunto de entrenamiento\n",
    "        inputs, labels = data\n",
    "        # Reiniciamos los gradientes\n",
    "        optimizer.zero_grad()\n",
    "        # Hacemos una pasada hacia adelante\n",
    "        outputs = model(inputs)\n",
    "        # Calculamos la pérdida\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Hacemos una pasada hacia atrás\n",
    "        loss.backward()\n",
    "        # Actualizamos los parámetros usando el step del optimizador\n",
    "        optimizer.step()\n",
    "        # Imprimimos estadísticas\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Época {epoch+1}, Pérdida: {running_loss/len(trainloader)}')\n",
    "    # Actualizamos el lr usando el step del planifcador de lr\n",
    "    scheduler.step()\n",
    "    print(f'Época {epoch+1}, Pérdida: {running_loss/len(trainloader)}, Tasa de aprendizaje: {scheduler.get_lr()[0]}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promediado de pesos\n",
    "\n",
    "El promediado de pesos, Stochastic Weight Averaging (SWA) permite mejorar la capacidad de generalización del modelo, promediando sus pesos durante un determinado número de iteraciones. \n",
    "\n",
    "El promedio se hace en base a varios puntos de la trayectoria de optimización. Vamos a ver un ejemplo comentado del uso de esta técnica en el ejemplo que hemos uso durante este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1, Pérdida: 2.303076273644977\n",
      "Época 1, Pérdida: 2.303076273644977, Tasa de aprendizaje: 0.01\n",
      "Época 2, Pérdida: 2.3029927542752318\n",
      "Época 2, Pérdida: 2.3029927542752318, Tasa de aprendizaje: 0.0001\n",
      "Época 3, Pérdida: 2.3028522071326174\n",
      "Época 3, Pérdida: 2.3028522071326174, Tasa de aprendizaje: 0.001\n",
      "Época 4, Pérdida: 2.3026863049973003\n",
      "Época 4, Pérdida: 2.3026863049973003, Tasa de aprendizaje: 1e-05\n",
      "Época 5, Pérdida: 2.3026124556046312\n",
      "Época 5, Pérdida: 2.3026124556046312, Tasa de aprendizaje: 0.0001\n",
      "Época 6, Pérdida: 2.3026079335785887\n",
      "Época 6, Pérdida: 2.3026079335785887, Tasa de aprendizaje: 1.0000000000000002e-06\n",
      "Época 7, Pérdida: 2.3026005593712067\n",
      "SWA: Época 7, Pérdida: 2.3026005593712067, Tasa de aprendizaje: 0.002426747431602186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegoandrade/.local/lib/python3.10/site-packages/torch/optim/swa_utils.py:286: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 8, Pérdida: 2.302675015176349\n",
      "SWA: Época 8, Pérdida: 2.302675015176349, Tasa de aprendizaje: 0.00807543310363525\n",
      "Época 9, Pérdida: 2.302821895960347\n",
      "SWA: Época 9, Pérdida: 2.302821895960347, Tasa de aprendizaje: 0.015166747979240275\n",
      "Época 10, Pérdida: 2.302918765855872\n",
      "SWA: Época 10, Pérdida: 2.302918765855872, Tasa de aprendizaje: 0.023025590457044103\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.optim import lr_scheduler\n",
    "# SGD: Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, foreach=False, nesterov=False)\n",
    "# Creamos un programador de tasa de aprendizaje\n",
    "# Cada 7 épocas, la tasa de aprendizaje se multiplicará por 0.1\n",
    "swa_model=torch.optim.swa_utils.AveragedModel(model)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "swa_start=5\n",
    "swa_scheduler = torch.optim.swa_utils.SWALR(optimizer, swa_lr=0.05)\n",
    "\n",
    "# Finalmente, entrenamos el modelo\n",
    "# Durante 10 épocas\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    # Para cada lote de datos\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Obtenemos las entradas y las etiquetas del lote del conjunto de entrenamiento\n",
    "        inputs, labels = data\n",
    "        # Reiniciamos los gradientes\n",
    "        optimizer.zero_grad()\n",
    "        # Hacemos una pasada hacia adelante\n",
    "        outputs = model(inputs)\n",
    "        # Calculamos la pérdida\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Hacemos una pasada hacia atrás\n",
    "        loss.backward()\n",
    "        # Actualizamos los parámetros usando el step del optimizador\n",
    "        optimizer.step()\n",
    "        # Imprimimos estadísticas\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Época {epoch+1}, Pérdida: {running_loss/len(trainloader)}')\n",
    "    # Actualizamos el lr usando el step del planifcador de lr\n",
    "    if epoch>swa_start:\n",
    "        swa_model.update_parameters(model)\n",
    "        swa_scheduler.step()\n",
    "        print(f'SWA: Época {epoch+1}, Pérdida: {running_loss/len(trainloader)}, Tasa de aprendizaje: {swa_scheduler.get_lr()[0]}')\n",
    "\n",
    "    else:\n",
    "        scheduler.step()\n",
    "        print(f'Época {epoch+1}, Pérdida: {running_loss/len(trainloader)}, Tasa de aprendizaje: {scheduler.get_lr()[0]}')\n",
    "\n",
    "torch.optim.swa_utils.update_bn(trainloader, swa_model)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
