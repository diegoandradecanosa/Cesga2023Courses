{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Data Parallel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistributedDataParallel (DDP) implementa el paralelismo de datos a nivel de módulo, lo que permite ejecutarlo en múltiples máquinas. Las aplicaciones que utilizan DDP deben crear múltiples procesos y crear una única instancia de DDP por proceso. DDP utiliza comunicaciones colectivas en el paquete ```torch.distributed``` para sincronizar gradientes y buffers. Específicamente, DDP registra un autograd hook para cada parámetro dado por ```model.parameters()```, y el hook se activa cuando se calcula el gradiente correspondiente en el paso de retropropagación. Luego, DDP utiliza esa señal para desencadenar la sincronización de gradientes entre los procesos. \n",
    "\n",
    "La forma recomendada de utilizar DDP es crear un proceso para cada réplica del modelo, donde una réplica del modelo puede abarcar múltiples dispositivos. Los procesos de DDP se pueden ubicar en la misma máquina o en máquinas diferentes, pero las GPU no se pueden compartir entre procesos. Este tutorial parte de un caso de uso básico de DDP y luego demuestra casos de uso más avanzados, como el guardado de modelos y la combinación de DDP con la división de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_demo(demo_fn, world_size):\n",
    "    mp.spawn(demo_fn,\n",
    "             args=(world_size,),\n",
    "             nprocs=world_size,\n",
    "             join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running basic DDP example on rank 1.\n",
      "Running basic DDP example on rank 0.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    assert n_gpus >= 2, f\"Requires at least 2 GPUs to run, but got {n_gpus}\"\n",
    "    world_size = n_gpus\n",
    "    run_demo(demo_basic, world_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
