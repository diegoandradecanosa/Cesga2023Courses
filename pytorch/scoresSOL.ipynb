{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Técnicas de Score de modelos en Python\n",
    "\n",
    "Las técnicas de Score (o puntuación) de modelos de ML evalúan su precisión. Habitualmente se basan en realizar algún tipo de comparación entre la salida obtenida y la salida deseada.\n",
    "\n",
    "Hay muchas técnicas de Score en ML, pero una familia de técnicas muy populares son las basadas en las Confusion matrices. Estas matrices cruzan las predicciones posibles, con las salidas deseadas, estableciendo una clasificación de la salida del modelo como:\n",
    "- TN: True Negative, el modelo predice correctamente un resultado negativo.\n",
    "- FN: False Negative, el modelo predice incorrectamente un resultado negativo.\n",
    "- TP: True Positive, el modelo predice correctamente un resultado positivo.\n",
    "- FP: False Positive, el modelo predice incorrectamente un resultado positivo.\n",
    "\n",
    "Las técnicas más comunes populares de este tipo son: precision, recall, f1-score y accuracy.\n",
    "\n",
    "En Pytorch no se implementa nativamente ninguna técnica de Score. Pero, en el ecosistema de Pytorch, hay un librería estándar de-facto que se puede usar para ello: *torchmetrics*\n",
    "\n",
    "Este librería tiene un API que implementa varias métricas con una interfaz común que proporciona los métodos: *update()*, *compute()* y *reset()*. Veamos un ejemplo completo de su uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchmetrics in /home/diegoandrade/.local/lib/python3.10/site-packages (0.11.4)\n",
      "Requirement already satisfied: torch>=1.8.1 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torchmetrics) (2.0.1)\n",
      "Requirement already satisfied: packaging in /home/diegoandrade/.local/lib/python3.10/site-packages (from torchmetrics) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torchmetrics) (1.23.5)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.7.91)\n",
      "Requirement already satisfied: filelock in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.10.6)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.7.101)\n",
      "Requirement already satisfied: sympy in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (8.5.0.96)\n",
      "Requirement already satisfied: jinja2 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: networkx in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (2.8.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.4.0.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->torchmetrics) (59.6.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->torchmetrics) (0.37.1)\n",
      "Requirement already satisfied: cmake in /home/diegoandrade/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/diegoandrade/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/diegoandrade/.local/lib/python3.10/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/diegoandrade/.local/lib/python3.10/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7651871740818024\n",
      "Epoch 1, F1-Score: 0.4421052634716034\n",
      "Epoch 2, Loss: 0.7613171994686126\n",
      "Epoch 2, F1-Score: 0.4421052634716034\n",
      "Epoch 3, Loss: 0.7579540908336639\n",
      "Epoch 3, F1-Score: 0.4421052634716034\n",
      "Epoch 4, Loss: 0.754697072505951\n",
      "Epoch 4, F1-Score: 0.44736841320991516\n",
      "Epoch 5, Loss: 0.7515209317207336\n",
      "Epoch 5, F1-Score: 0.45052632689476013\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics import F1Score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Definimos un modelo muy simple para clasificación binaria\n",
    "class BinaryClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassificationModel, self).__init__()\n",
    "        self.linear = nn.Linear(10, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = torch.sigmoid(self.linear(x))\n",
    "        return output\n",
    "\n",
    "# Inicializamos el modelo, la métrica y el optimizador\n",
    "model = BinaryClassificationModel()\n",
    "metric = F1Score(task='binary',num_classes=1, threshold=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Creamos un dataset de ejemplo aleatorio\n",
    "inputs = torch.randn(100, 10)\n",
    "targets = torch.randint(0, 2, (100,)).float()  # Binary targets\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=10)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(5):  # 5 épocas\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = nn.BCELoss()(outputs.view(-1), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # Actualizamos la métrica\n",
    "        metric(outputs.view(-1), labels)\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(dataloader)}\")\n",
    "    print(f\"Epoch {epoch+1}, F1-Score: {metric.compute()}\")\n",
    "\n",
    "# Reinicializamos la métrica para la siguiente época\n",
    "metric.reset()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos usar una estructura de tipo *MetricCollection* para recopilar dos métricas a la vez. Veamos una adaptación del ejemplo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.743862920999527\n",
      "Epoch 1, Metrics: {'BinaryHammingDistance': tensor(0.5700), 'BinaryF1Score': tensor(0.5043)}\n",
      "Epoch 2, Loss: 0.741177785396576\n",
      "Epoch 2, Metrics: {'BinaryHammingDistance': tensor(0.5700), 'BinaryF1Score': tensor(0.5043)}\n",
      "Epoch 3, Loss: 0.7390010833740235\n",
      "Epoch 3, Metrics: {'BinaryHammingDistance': tensor(0.5700), 'BinaryF1Score': tensor(0.5043)}\n",
      "Epoch 4, Loss: 0.7369191586971283\n",
      "Epoch 4, Metrics: {'BinaryHammingDistance': tensor(0.5700), 'BinaryF1Score': tensor(0.5043)}\n",
      "Epoch 5, Loss: 0.7349006116390229\n",
      "Epoch 5, Metrics: {'BinaryHammingDistance': tensor(0.5800), 'BinaryF1Score': tensor(0.5000)}\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import HammingDistance, F1Score, MetricCollection\n",
    "\n",
    "\n",
    "# Inicializamos el modelo, la métrica y el optimizador\n",
    "model = BinaryClassificationModel()\n",
    "metrics = MetricCollection([HammingDistance(task='binary'), F1Score(task='binary',num_classes=1, threshold=0.5)])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Creamos un dataset de ejemplo aleatorio\n",
    "inputs = torch.randn(100, 10)\n",
    "targets = torch.randint(0, 2, (100,)).long()  # Binary targets\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=10)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(5):  # 5 épocas\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = nn.BCELoss()(outputs.view(-1), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # Actualizamos la métrica\n",
    "        pred_labels = torch.round(outputs.view(-1))\n",
    "        metrics(pred_labels, labels)\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(dataloader)}\")\n",
    "    print(f\"Epoch {epoch+1}, Metrics: {metrics.compute()}\")\n",
    "    # Reinicializamos la métrica para la siguiente época\n",
    "    metrics.reset()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "\n",
    "Utilizando como el base, el código resultante del ejercicio al final del notebook *optimizers.ipynb*, haz los cambios pertinentes para calcular la Hamming Distance y el BinaryF1Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch 1, Loss: 72.85159102678298\n",
      "Epoch 1, Metrics: {'MulticlassHammingDistance': tensor(0.5833), 'MulticlassF1Score': tensor(0.4167)}\n",
      "Epoch 2, Loss: 64.53456679806114\n",
      "Epoch 2, Metrics: {'MulticlassHammingDistance': tensor(0.3750), 'MulticlassF1Score': tensor(0.6250)}\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchmetrics import HammingDistance, F1Score, MetricCollection\n",
    "\n",
    "\n",
    "# Inicializamos el modelo, la métrica y el optimizador\n",
    "metrics = MetricCollection([HammingDistance(task='multiclass', num_classes=10), F1Score(task='multiclass',num_classes=10, threshold=0.5)])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Define the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define the loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the training function\n",
    "def train(net, trainloader, optimizer, num_epochs=2):\n",
    "    loss_values = []\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # save losses to plot later\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                loss_values.append(running_loss / 2000)\n",
    "                running_loss = 0.0\n",
    "                metrics(torch.argmax(outputs,dim=1), labels)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(dataloader)}\")\n",
    "        print(f\"Epoch {epoch+1}, Metrics: {metrics.compute()}\")\n",
    "        # Reinicializamos la métrica para la siguiente época\n",
    "        metrics.reset()\n",
    "\n",
    "    return loss_values\n",
    "\n",
    "# SGD\n",
    "net_SGD = Net()\n",
    "optimizer_SGD = optim.SGD(net_SGD.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_SGD = train(net_SGD, trainloader, optimizer_SGD)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
