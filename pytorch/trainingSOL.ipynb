{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación y composición de arquitecturas de red\n",
    "\n",
    "En este notebook vamos a ver cómo crear una arquitectura de red para resolver un problema determinado, entrenarla y validar su funcionamiento.\n",
    "\n",
    "Los elementos necesarios para ello son los siguientes:\n",
    "\n",
    "- Contenedores \n",
    "- Capas predefinidas\n",
    "- Optimizadores\n",
    "- Funciones de pérdida\n",
    "- Definición de bucles de entrenamiento\n",
    "\n",
    "Vamos a recordar los pasos básicos para entender un bucle de entrenamiento:\n",
    "\n",
    "- Definir el modelo a entrenar\n",
    "    - Definición de la arquitectura\n",
    "    - De la pasada forward\n",
    "\n",
    "- Definir el bucle de entrenamiento\n",
    "    - Cargar un conjunto de datos, y dividirlo en:\n",
    "        - Conjunto de entrenamiento\n",
    "        - Conjunto de validación\n",
    "    - Construcción del paso (step) de entrenamiento\n",
    "        - Optimizador\n",
    "        - Función de pérdida\n",
    "    - Comprobación de la precisión del modelo\n",
    "\n",
    "\n",
    "## Contenedores para la construcción de modelos en Pytorch\n",
    "\n",
    "Vamos a empezar con el uso de contenedores en Pytorch para la construcción de modelos. En Pytorch, utilizamos *Modules* para la definición de arquitecturas de modelos de entrenamiento. Los *Modules* facilitan la construcción de modelos, la especificación de los parámetros que son aprendibles, la integración con el sistema de *Autograd* y la especificación del comportamiento de la pasada *Forward*.\n",
    "\n",
    "Primero hacemos algunos imports, necesarios para los ejemplos de este notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer una definición del modelo con el contenedor *Module*. Este mecanismo requiere utilizar el constructor para definir la arquitectura del modelo, y una implementación específica para la pasada *Forward*. La arquitectura del modelo tiene:\n",
    "\n",
    "- Una capa de aplanamiento (*flatten*)\n",
    "- Una capa de tipo *Linear* (784 (28x28) -> 128)\n",
    "- Una función de activación *ReLU*\n",
    "- Otra capa de tipo *Linear* (128 -> 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la red neuronal como un módulo personalizado\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Definir las capas de la red\n",
    "        self.flatten = nn.Flatten() # Capa de aplanamiento\n",
    "        self.fc1 = nn.Linear(784, 128) # Capa completamente conectada\n",
    "        self.relu = nn.ReLU() # Función de activación ReLU\n",
    "        self.fc2 = nn.Linear(128, 10) # Capa completamente conectada para la salida\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Definir el paso hacia adelante a través de la red\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo anterior tiene una arquitectura secuencial (lineal) y la pasada *Forward* consiste simplemente en conectar las salidas de una capa con las entradas de la siguiente capa. Este tipo de arquitectura es la más simple, pero también una de las más comunes, así que Pytorch proporciona un mecanismo simplificado para la definición de una arquitectura de este tipo (*nn.Sequential*) en el que no es necesario definir la pasada *Forward*. Veamos el ejemplo equivalente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la arquitectura de la red utilizando Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),  # Capa de aplanamiento\n",
    "    nn.Linear(784, 128),  # Capa completamente conectada\n",
    "    nn.ReLU(),  # Función de activación ReLU\n",
    "    nn.Linear(128, 10)  # Capa completamente conectada para la salida\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque para un modelo simple, la inspección del código de su definición puede ser suficiente para visualizar la arquitectura del modelo. Existen varias soluciones para hacer una visualización del modelo más amigable. Vamos a ver un ejemplo de dos de ellas:\n",
    "- torchsummary\n",
    "- torchviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchsummary in /home/diegoandrade/.local/lib/python3.10/site-packages (1.5.1)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 128]         100,480\n",
      "              ReLU-3                  [-1, 128]               0\n",
      "            Linear-4                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.39\n",
      "Estimated Total Size (MB): 0.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "#Visualizamos la arquitectura de la red\n",
    "model.to('cuda')\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchviz in /home/diegoandrade/.local/lib/python3.10/site-packages (0.0.2)\n",
      "Requirement already satisfied: graphviz in /home/diegoandrade/.local/lib/python3.10/site-packages (from torchviz) (0.20.1)\n",
      "Requirement already satisfied: torch in /home/diegoandrade/.local/lib/python3.10/site-packages (from torchviz) (2.0.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (11.7.101)\n",
      "Requirement already satisfied: jinja2 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (3.1.2)\n",
      "Requirement already satisfied: filelock in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (3.10.6)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (1.11.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (10.2.10.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (11.7.91)\n",
      "Requirement already satisfied: networkx in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (2.8.8)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/diegoandrade/.local/lib/python3.10/site-packages (from torch->torchviz) (10.9.0.58)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchviz) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchviz) (59.6.0)\n",
      "Requirement already satisfied: cmake in /home/diegoandrade/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->torchviz) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/diegoandrade/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->torchviz) (16.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/diegoandrade/.local/lib/python3.10/site-packages (from jinja2->torch->torchviz) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/diegoandrade/.local/lib/python3.10/site-packages (from sympy->torch->torchviz) (1.3.0)\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"340pt\" height=\"413pt\"\n",
       " viewBox=\"0.00 0.00 340.00 413.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 409)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-409 336,-409 336,4 -4,4\"/>\n",
       "<!-- 140215991811136 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140215991811136</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"199,-31 134,-31 134,0 199,0 199,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (1, 10)</text>\n",
       "</g>\n",
       "<!-- 140212730535872 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140212730535872</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"217,-86 116,-86 116,-67 217,-67 217,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 140212730535872&#45;&gt;140215991811136 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140212730535872&#45;&gt;140215991811136</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.5,-66.79C166.5,-60.07 166.5,-50.4 166.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170,-41.19 166.5,-31.19 163,-41.19 170,-41.19\"/>\n",
       "</g>\n",
       "<!-- 140212788394064 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140212788394064</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-141 0,-141 0,-122 101,-122 101,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140212788394064&#45;&gt;140212730535872 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140212788394064&#45;&gt;140212730535872</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.14,-121.98C87.8,-113.46 116.75,-100.23 138.24,-90.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"139.88,-93.51 147.52,-86.17 136.97,-87.14 139.88,-93.51\"/>\n",
       "</g>\n",
       "<!-- 140212835249312 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140212835249312</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-207 23.5,-207 23.5,-177 77.5,-177 77.5,-207\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">3.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (10)</text>\n",
       "</g>\n",
       "<!-- 140212835249312&#45;&gt;140212788394064 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140212835249312&#45;&gt;140212788394064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.84C50.5,-169.21 50.5,-159.7 50.5,-151.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.27 50.5,-141.27 47,-151.27 54,-151.27\"/>\n",
       "</g>\n",
       "<!-- 140212788391520 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140212788391520</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-141 119,-141 119,-122 214,-122 214,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"166.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140212788391520&#45;&gt;140212730535872 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140212788391520&#45;&gt;140212730535872</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.5,-121.75C166.5,-114.8 166.5,-104.85 166.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170,-96.09 166.5,-86.09 163,-96.09 170,-96.09\"/>\n",
       "</g>\n",
       "<!-- 140212788383840 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140212788383840</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"213,-201.5 112,-201.5 112,-182.5 213,-182.5 213,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 140212788383840&#45;&gt;140212788391520 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140212788383840&#45;&gt;140212788391520</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.09,-182.37C163.65,-174.25 164.5,-161.81 165.21,-151.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"168.72,-151.38 165.91,-141.17 161.73,-150.91 168.72,-151.38\"/>\n",
       "</g>\n",
       "<!-- 140212726412240 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140212726412240</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"118,-267.5 17,-267.5 17,-248.5 118,-248.5 118,-267.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"67.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140212726412240&#45;&gt;140212788383840 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140212726412240&#45;&gt;140212788383840</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M80.31,-248.37C95.89,-237.87 122.43,-220 141.12,-207.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"143.25,-210.19 149.59,-201.7 139.34,-204.38 143.25,-210.19\"/>\n",
       "</g>\n",
       "<!-- 140211764897216 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140211764897216</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"94.5,-339 40.5,-339 40.5,-309 94.5,-309 94.5,-339\"/>\n",
       "<text text-anchor=\"middle\" x=\"67.5\" y=\"-327\" font-family=\"monospace\" font-size=\"10.00\">1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"67.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\"> (128)</text>\n",
       "</g>\n",
       "<!-- 140211764897216&#45;&gt;140212726412240 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140211764897216&#45;&gt;140212726412240</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.5,-308.8C67.5,-299.7 67.5,-287.79 67.5,-277.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"71,-277.84 67.5,-267.84 64,-277.84 71,-277.84\"/>\n",
       "</g>\n",
       "<!-- 140212726404512 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140212726404512</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"213,-267.5 136,-267.5 136,-248.5 213,-248.5 213,-267.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 140212726404512&#45;&gt;140212788383840 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140212726404512&#45;&gt;140212788383840</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.88,-248.37C171.14,-239.07 168.31,-223.98 166.04,-211.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"169.45,-211.09 164.17,-201.91 162.57,-212.38 169.45,-211.09\"/>\n",
       "</g>\n",
       "<!-- 140212726413392 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140212726413392</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"225,-333.5 124,-333.5 124,-314.5 225,-314.5 225,-333.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140212726413392&#45;&gt;140212726404512 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140212726413392&#45;&gt;140212726404512</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.5,-314.37C174.5,-305.16 174.5,-290.29 174.5,-278.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178,-277.91 174.5,-267.91 171,-277.91 178,-277.91\"/>\n",
       "</g>\n",
       "<!-- 140211764900896 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140211764900896</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"216,-405 133,-405 133,-375 216,-375 216,-405\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-393\" font-family=\"monospace\" font-size=\"10.00\">1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\"> (128, 784)</text>\n",
       "</g>\n",
       "<!-- 140211764900896&#45;&gt;140212726413392 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140211764900896&#45;&gt;140212726413392</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.5,-374.8C174.5,-365.7 174.5,-353.79 174.5,-343.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178,-343.84 174.5,-333.84 171,-343.84 178,-343.84\"/>\n",
       "</g>\n",
       "<!-- 140212788393440 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140212788393440</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"316,-141 239,-141 239,-122 316,-122 316,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"277.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 140212788393440&#45;&gt;140212730535872 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140212788393440&#45;&gt;140212730535872</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M259.67,-121.98C241.89,-113.5 214.35,-100.35 193.82,-90.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"195.19,-87.32 184.66,-86.17 192.17,-93.64 195.19,-87.32\"/>\n",
       "</g>\n",
       "<!-- 140212788379856 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140212788379856</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"332,-201.5 231,-201.5 231,-182.5 332,-182.5 332,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140212788379856&#45;&gt;140212788393440 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140212788379856&#45;&gt;140212788393440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M280.91,-182.37C280.35,-174.25 279.5,-161.81 278.79,-151.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282.27,-150.91 278.09,-141.17 275.28,-151.38 282.27,-150.91\"/>\n",
       "</g>\n",
       "<!-- 140212835254032 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140212835254032</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"320,-273 243,-273 243,-243 320,-243 320,-273\"/>\n",
       "<text text-anchor=\"middle\" x=\"281.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\">3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"281.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\"> (10, 128)</text>\n",
       "</g>\n",
       "<!-- 140212835254032&#45;&gt;140212788379856 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140212835254032&#45;&gt;140212788379856</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M281.5,-242.8C281.5,-233.7 281.5,-221.79 281.5,-211.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"285,-211.84 281.5,-201.84 278,-211.84 285,-211.84\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f86945c2c50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install torchviz\n",
    "import torchviz\n",
    "from torch.autograd import Variable\n",
    "\n",
    "model.to('cuda')\n",
    "x = Variable(torch.randn(1, 1, 28, 28)).to('cuda')\n",
    "torchviz.make_dot(model(x), params=dict(model.named_parameters()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los métodos *children* (*named_children*), *modules* (*named_modules*), y *parameters* (*named_parameters*) se pueden usar para recorrer los componentes de un módulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named children =========\n",
      "0 Flatten(start_dim=1, end_dim=-1)\n",
      "1 Linear(in_features=784, out_features=128, bias=True)\n",
      "2 ReLU()\n",
      "3 Linear(in_features=128, out_features=10, bias=True)\n",
      "Named modules =========\n",
      " Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "0 Flatten(start_dim=1, end_dim=-1)\n",
      "1 Linear(in_features=784, out_features=128, bias=True)\n",
      "2 ReLU()\n",
      "3 Linear(in_features=128, out_features=10, bias=True)\n",
      "Named parameters =========\n",
      "1.weight Parameter containing:\n",
      "tensor([[-0.0279,  0.0238, -0.0267,  ..., -0.0285,  0.0003,  0.0143],\n",
      "        [-0.0064,  0.0147,  0.0150,  ..., -0.0045,  0.0008,  0.0212],\n",
      "        [-0.0321,  0.0037,  0.0028,  ..., -0.0171,  0.0297, -0.0306],\n",
      "        ...,\n",
      "        [-0.0061, -0.0194, -0.0299,  ...,  0.0120,  0.0292,  0.0327],\n",
      "        [ 0.0201,  0.0049,  0.0256,  ...,  0.0232, -0.0117, -0.0318],\n",
      "        [-0.0313, -0.0059, -0.0209,  ..., -0.0288,  0.0139, -0.0348]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "1.bias Parameter containing:\n",
      "tensor([ 0.0248,  0.0305, -0.0023, -0.0192,  0.0004, -0.0066, -0.0293, -0.0280,\n",
      "        -0.0233,  0.0074, -0.0075,  0.0273,  0.0126, -0.0054,  0.0191,  0.0022,\n",
      "         0.0007, -0.0090, -0.0317,  0.0011, -0.0247,  0.0023, -0.0270, -0.0125,\n",
      "         0.0213,  0.0328,  0.0229, -0.0233, -0.0351, -0.0192, -0.0251, -0.0278,\n",
      "         0.0070, -0.0060,  0.0102,  0.0355, -0.0353, -0.0293,  0.0127, -0.0283,\n",
      "         0.0104, -0.0046,  0.0048,  0.0254, -0.0139,  0.0174, -0.0338, -0.0126,\n",
      "        -0.0082, -0.0155, -0.0111,  0.0184, -0.0355, -0.0068, -0.0190, -0.0356,\n",
      "         0.0153, -0.0097,  0.0108,  0.0012, -0.0284, -0.0202,  0.0145, -0.0220,\n",
      "         0.0218, -0.0102, -0.0297,  0.0187, -0.0072, -0.0134, -0.0048,  0.0187,\n",
      "        -0.0314, -0.0332, -0.0194,  0.0261, -0.0254,  0.0059,  0.0195,  0.0291,\n",
      "         0.0054,  0.0049,  0.0050,  0.0141, -0.0124,  0.0035,  0.0266, -0.0307,\n",
      "        -0.0177, -0.0267, -0.0239, -0.0296, -0.0191,  0.0149,  0.0068,  0.0332,\n",
      "         0.0308, -0.0349,  0.0058, -0.0275,  0.0160,  0.0138, -0.0239,  0.0019,\n",
      "         0.0073,  0.0047, -0.0045,  0.0262,  0.0072,  0.0002, -0.0211,  0.0114,\n",
      "        -0.0079,  0.0082,  0.0039,  0.0150, -0.0105, -0.0305,  0.0055,  0.0305,\n",
      "         0.0109, -0.0203, -0.0105,  0.0091,  0.0114, -0.0088, -0.0204, -0.0225],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "3.weight Parameter containing:\n",
      "tensor([[ 0.0398,  0.0373, -0.0413,  ..., -0.0696, -0.0166, -0.0069],\n",
      "        [-0.0256,  0.0176,  0.0791,  ...,  0.0415,  0.0365,  0.0544],\n",
      "        [-0.0145,  0.0244,  0.0626,  ...,  0.0807, -0.0370, -0.0818],\n",
      "        ...,\n",
      "        [ 0.0296,  0.0092, -0.0566,  ...,  0.0101, -0.0562, -0.0531],\n",
      "        [-0.0865, -0.0212,  0.0414,  ..., -0.0286,  0.0711, -0.0263],\n",
      "        [ 0.0247,  0.0168, -0.0134,  ..., -0.0696, -0.0772,  0.0758]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "3.bias Parameter containing:\n",
      "tensor([-0.0118, -0.0366, -0.0546, -0.0643,  0.0224,  0.0324,  0.0847,  0.0308,\n",
      "        -0.0425, -0.0690], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Named children =========\")\n",
    "for name, param in model.named_children():\n",
    "    print(name, param)\n",
    "print(\"Named modules =========\")\n",
    "for name, param in model.named_modules():\n",
    "    print(name, param)\n",
    "print(\"Named parameters =========\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucle de entrenamiento\n",
    "\n",
    "Una vez definida la arquitectura del modelo, el siguiente paso consiste en la definición del buclee de entreamiento. Para ello, tenemos que asociar al modelo un optimizador. Pytorch implementa de forma nativa un gran número de algoritmos de optimización. El bucle de entrenamiento (step) consta de las siguientes etapas:\n",
    "- Carga de la entrada\n",
    "- Realización de la inferencia\n",
    "- Cálculo de la función de pérdida (*loss function*)\n",
    "- Reinicio de los gradientes de los parámetros\n",
    "- Ejecución de la pasada *Backward* usando la función *backward()* asociada a la función  de pérdida para calcular los gradientes\n",
    "- Ejecuión de la función *step()* asociada al optimizador para actualizar los gradientes\n",
    "\n",
    "Vamos a ver ahora un ejemplo comentado de un modelo convolucional utilizado para entrenar el conjunto de datos MNIST. La definición de alguna de sus capas, y de otros elementos, es algo que todavía no hemos visto a estas alturas de la presentación, pero este código nos servirá para tener una visión general del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 11.58234925946193\n",
      "Epoch 2/10, Loss: 4.030419327493416\n",
      "Epoch 3/10, Loss: 2.9322212804863446\n",
      "Epoch 4/10, Loss: 2.3562217915871506\n",
      "Epoch 5/10, Loss: 1.992010511283173\n",
      "Epoch 6/10, Loss: 1.7221986807491592\n",
      "Epoch 7/10, Loss: 1.526840920315813\n",
      "Epoch 8/10, Loss: 1.36126474872716\n",
      "Epoch 9/10, Loss: 1.2343973995093058\n",
      "Epoch 10/10, Loss: 1.1274491242174782\n",
      "Accuracy on test set: 88.66%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Fijamos una semilla para que los resultados sean reproducibles\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Cargamos los datos: MNIST dataset\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "# Creamos los dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Definimos la función linear y relu en base a tensores\n",
    "def linear(x, weight, bias):\n",
    "    return torch.matmul(x, weight.t()) + bias\n",
    "\n",
    "def relu(x):\n",
    "    return torch.max(x, torch.zeros_like(x))\n",
    "\n",
    "# Definición de la red neuronal\n",
    "def simple_net(x):\n",
    "    x = relu(linear(x, weight1, bias1))\n",
    "    x = linear(x, weight2, bias2)\n",
    "    return x\n",
    "\n",
    "# Inicialización de los parámetros aleatoriamente\n",
    "weight1 = torch.randn(128, 784, requires_grad=True)\n",
    "bias1 = torch.randn(128, requires_grad=True)\n",
    "weight2 = torch.randn(10, 128, requires_grad=True)\n",
    "bias2 = torch.randn(10, requires_grad=True)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        # Flatten the images into a 1D tensor\n",
    "        images = images.view(images.size(0), -1)\n",
    "\n",
    "        # Zero the gradients\n",
    "        weight1.grad = None\n",
    "        bias1.grad = None\n",
    "        weight2.grad = None\n",
    "        bias2.grad = None\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = simple_net(images)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        with torch.no_grad():\n",
    "            weight1 -= learning_rate * weight1.grad\n",
    "            bias1 -= learning_rate * bias1.grad\n",
    "            weight2 -= learning_rate * weight2.grad\n",
    "            bias2 -= learning_rate * bias2.grad\n",
    "\n",
    "        # Track the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.view(images.size(0), -1)\n",
    "    outputs = simple_net(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print accuracy on the test set\n",
    "print(f\"Accuracy on test set: {100 * correct / total}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1250,  4.4208,  1.2268], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Hereda de nn.Module\n",
    "class MyLinear(nn.Module):\n",
    "  # Definición del modelo\n",
    "  def __init__(self, in_features, out_features):\n",
    "    super().__init__()\n",
    "    self.weight = nn.Parameter(torch.randn(in_features, out_features))\n",
    "    self.bias = nn.Parameter(torch.randn(out_features))\n",
    "  # Definición de la operación forward\n",
    "  def forward(self, input):\n",
    "    return (input @ self.weight) + self.bias\n",
    "  \n",
    "m = MyLinear(4, 3)\n",
    "sample_input = torch.randn(4)\n",
    "m(sample_input)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 11.58234925946193\n",
      "Epoch 2/10, Loss: 4.030419327493416\n",
      "Epoch 3/10, Loss: 2.9322212804863446\n",
      "Epoch 4/10, Loss: 2.3562217915871506\n",
      "Epoch 5/10, Loss: 1.992010511283173\n",
      "Epoch 6/10, Loss: 1.7221986807491592\n",
      "Epoch 7/10, Loss: 1.526840920315813\n",
      "Epoch 8/10, Loss: 1.36126474872716\n",
      "Epoch 9/10, Loss: 1.2343973995093058\n",
      "Epoch 10/10, Loss: 1.1274491242174782\n",
      "Accuracy on test set: 88.66%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegoandrade/.local/lib/python3.10/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307972\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.614601\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.545359\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.280141\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.473983\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.522550\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.177747\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.486807\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.209534\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.353559\n",
      "\n",
      "Test set: Average loss: 0.1437, Accuracy: 9561/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.323789\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.397856\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.349941\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.145273\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.267328\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.217238\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.266196\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.200315\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.151066\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.074906\n",
      "\n",
      "Test set: Average loss: 0.0876, Accuracy: 9707/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.191675\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.125606\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.150323\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.164400\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.055899\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.072254\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.080899\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.178080\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.050009\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.073883\n",
      "\n",
      "Test set: Average loss: 0.0671, Accuracy: 9789/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.163052\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.156731\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.037726\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.020750\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.125221\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.130879\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.146688\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.056350\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.127562\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.036611\n",
      "\n",
      "Test set: Average loss: 0.0529, Accuracy: 9830/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.027142\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.019747\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.049651\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.154662\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.111160\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.104372\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.059633\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.157477\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.075159\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.255171\n",
      "\n",
      "Test set: Average loss: 0.0459, Accuracy: 9843/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.037513\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.019522\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.021280\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.049756\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.096751\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.114688\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.089040\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.016960\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.065375\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.028396\n",
      "\n",
      "Test set: Average loss: 0.0414, Accuracy: 9859/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.048882\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.018553\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.041286\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.118306\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.132609\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.097778\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.029910\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.118811\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.040738\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.070562\n",
      "\n",
      "Test set: Average loss: 0.0430, Accuracy: 9852/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.004916\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.023725\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.072785\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.105275\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.047379\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.036487\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.090782\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.038044\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.010635\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.065411\n",
      "\n",
      "Test set: Average loss: 0.0365, Accuracy: 9884/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.011165\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.026430\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.080970\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.036347\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.044654\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.104937\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.012904\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.016603\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.022211\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.055116\n",
      "\n",
      "Test set: Average loss: 0.0333, Accuracy: 9878/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.066927\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.014198\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.032692\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.021163\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.116359\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.017115\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.085196\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.060523\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.011591\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.025761\n",
      "\n",
      "Test set: Average loss: 0.0350, Accuracy: 9878/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Definición de la arquitectura del modelo\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "#Definición de la operación forward\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = nn.functional.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "# Carga de los datos del dataset MNIST\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "test_dataset = datasets.MNIST('./data', train=False, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "# Separación de los datos en batches, para entrenamiento y test\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Inicialización de la red y el optimizador\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "# Definición de una función para entrenar el modelo\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = nn.functional.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "# Definición de una función para validar el modelo\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += nn.functional.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "# Bucle en el que se entrena el modelo y se evalúa durante 11 épocas\n",
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo anterior, hemos usado varios elementos de Pytorch que sabemos que existen a nivel conceptual, pero para los que a estas alturas todavía no hemos visto los elementos del API que permiten su uso y definición. Algunos de ellos son:\n",
    "- Tipos de capas predefinidos\n",
    "- Optimizadores\n",
    "- Funciones de pérdida\n",
    "\n",
    "## Tipos de capas en Pytorch\n",
    "\n",
    "Vamos a empezar por ver algunos ejemplos de funciones del API de Pytorch que permiten la definición de capas. Existen varias categorías de capas según su tipo:\n",
    "- Lineales\n",
    "- Convolucionales\n",
    "- Pooling\n",
    "- Padding\n",
    "- Normalización\n",
    "- Dropout\n",
    "- Para redes recurrentes\n",
    "- Para redes transformer\n",
    "\n",
    "Empecemos con algún ejemplo ilustrativo de las capas lineales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight matrix:  Parameter containing:\n",
      "tensor([[-0.0308, -0.4733, -0.0917],\n",
      "        [ 0.3219, -0.1953,  0.2930]], requires_grad=True)\n",
      "Bias matrix:  Parameter containing:\n",
      "tensor([-0.3314, -0.2079], requires_grad=True)\n",
      "Input Data:\n",
      "tensor([[-0.3482, -0.9231,  0.6383],\n",
      "        [ 1.8991,  0.3206,  1.5234],\n",
      "        [ 0.2983, -0.5543,  0.6186],\n",
      "        [ 0.2750,  1.6511, -0.6495]])\n",
      "\n",
      "Output Data:\n",
      "tensor([[ 0.0577,  0.0473],\n",
      "        [-0.6813,  0.7870],\n",
      "        [-0.1350,  0.1776],\n",
      "        [-1.0618, -0.6322]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output Data 2:\n",
      "tensor([[ 0.0577,  0.0473],\n",
      "        [-0.6813,  0.7870],\n",
      "        [-0.1350,  0.1776],\n",
      "        [-1.0618, -0.6322]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Definimos una capa lineal simple\n",
    "linear_layer = nn.Linear(3, 2)  # Tamaño entrada : 3, salida: 2\n",
    "print(\"Weight matrix: \", linear_layer.weight)\n",
    "print(\"Bias matrix: \", linear_layer.bias)\n",
    "\n",
    "# Crear input data\n",
    "input_data = torch.randn(4,3)\n",
    "# Calcular la salida de la capa lineal\n",
    "output_data = linear_layer(input_data)\n",
    "output_data2 = input_data @ linear_layer.weight.t() + linear_layer.bias\n",
    "# Imprimir los datos de entrada y salida\n",
    "print(\"Input Data:\")\n",
    "print(input_data)\n",
    "print(\"\\nOutput Data:\")\n",
    "print(output_data)\n",
    "print(\"\\nOutput Data 2:\")\n",
    "print(output_data2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En muchos tipos de capas de Pytorch existe una versión *lazy* para la cual no es necesario proporciona la forma (*shape*) de la entrada. Veamos un ejemplo con *LazyLinear*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight matrix:  <UninitializedParameter>\n",
      "Bias matrix:  <UninitializedParameter>\n",
      "Weight matrix:  Parameter containing:\n",
      "tensor([[-0.3125,  0.4832,  0.1145],\n",
      "        [-0.4073,  0.2337, -0.4187]], requires_grad=True)\n",
      "Bias matrix:  Parameter containing:\n",
      "tensor([-0.1197,  0.4561], requires_grad=True)\n",
      "Input Data:\n",
      "tensor([[-0.1735,  0.1959,  2.2416],\n",
      "        [ 1.7223,  0.4172,  1.0134],\n",
      "        [ 0.4464,  0.2062,  0.8306],\n",
      "        [ 1.6061,  0.4793, -1.5812]])\n",
      "\n",
      "Output Data:\n",
      "tensor([[ 0.2859, -0.3660],\n",
      "        [-0.3403, -0.5721],\n",
      "        [-0.0645, -0.0253],\n",
      "        [-0.5711,  0.5761]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output Data 2:\n",
      "tensor([[ 0.2859, -0.3660],\n",
      "        [-0.3403, -0.5721],\n",
      "        [-0.0645, -0.0253],\n",
      "        [-0.5711,  0.5761]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Definimos una capa lineal simple (versión Lazy)\n",
    "linear_layer = nn.LazyLinear(2)  # Tamaño entrada : desconocido, salida: 2\n",
    "# Imprimimos los pesos y los bias antes de la primera llamada a la capa lineal\n",
    "print(\"Weight matrix: \", linear_layer.weight)\n",
    "print(\"Bias matrix: \", linear_layer.bias)\n",
    "\n",
    "# Crear input data\n",
    "input_data = torch.randn(4,3)\n",
    "# Calcular la salida de la capa lineal\n",
    "output_data = linear_layer(input_data)\n",
    "output_data2 = input_data @ linear_layer.weight.t() + linear_layer.bias\n",
    "\n",
    "# Imprimimos los pesos y los bias después de la primera llamada a la capa lineal\n",
    "print(\"Weight matrix: \", linear_layer.weight)\n",
    "print(\"Bias matrix: \", linear_layer.bias)\n",
    "\n",
    "# Imprimir los datos de entrada y salida\n",
    "print(\"Input Data:\")\n",
    "print(input_data)\n",
    "print(\"\\nOutput Data:\")\n",
    "print(output_data)\n",
    "print(\"\\nOutput Data 2:\")\n",
    "print(output_data2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las capas convolucionales están relacionadas con aplicaciones de procesamiento de señal, a menudo, imágenes y vídeo, y además de la familia de las capas convolucionales, tenemos también tipos de capas relacionados como son: Pooling, Padding, Normalización y Dropout. Vemos algunos ejemplos ilustrativos de estas capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de los datos y datos de entrada:\n",
      "torch.Size([1, 3, 32, 32])\n",
      "tensor([[[[ 2.2536,  1.4902, -0.3772,  ...,  0.3567,  1.3310, -1.2155],\n",
      "          [ 0.2564,  0.1282,  0.4325,  ...,  0.6141, -0.2540, -1.3376],\n",
      "          [-0.2065, -1.5369, -0.2166,  ..., -0.4992, -1.3978, -1.2252],\n",
      "          ...,\n",
      "          [ 0.4004,  1.2814,  1.0165,  ...,  1.3790, -0.1283,  0.1537],\n",
      "          [-0.4196, -0.9416, -0.1998,  ..., -0.2781,  1.3424,  0.3440],\n",
      "          [ 1.3564,  1.7729, -1.4882,  ..., -0.2471, -0.6083, -1.1830]],\n",
      "\n",
      "         [[ 2.5222,  0.5607, -0.4229,  ..., -1.1158, -0.5386,  1.1211],\n",
      "          [ 1.3293, -0.0855, -0.8541,  ...,  0.4937,  0.7172, -0.6303],\n",
      "          [ 0.4190,  0.9188,  0.8026,  ...,  0.4096, -0.7371, -0.7299],\n",
      "          ...,\n",
      "          [-0.4155, -0.6191,  0.3465,  ...,  0.1378, -0.1317,  0.0272],\n",
      "          [-0.0907, -0.1095, -1.1265,  ..., -1.1798, -0.5699, -1.4068],\n",
      "          [ 0.9270, -1.8275, -3.3843,  ...,  0.0326, -0.4545, -1.6691]],\n",
      "\n",
      "         [[-2.2827, -0.4983, -0.3818,  ..., -1.1605,  0.3601, -0.8566],\n",
      "          [ 0.9215, -0.4394,  0.4752,  ..., -0.4555, -0.0879, -0.8892],\n",
      "          [-0.9365,  0.1277, -0.7306,  ..., -0.1543, -0.1378, -1.0338],\n",
      "          ...,\n",
      "          [ 0.2583, -1.8021,  0.1480,  ...,  1.8682,  0.6526,  0.4384],\n",
      "          [ 0.1593, -1.2646,  0.4764,  ..., -3.5368,  0.1218,  1.2950],\n",
      "          [ 1.7984, -1.1063, -2.6090,  ..., -1.7713,  2.0184, -0.7563]]]])\n",
      "Capa convolucional (pesos y bias):\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0654, -0.1014,  0.1520],\n",
      "          [ 0.1154,  0.0828, -0.0649],\n",
      "          [-0.1005,  0.0669, -0.1351]],\n",
      "\n",
      "         [[-0.0712,  0.1236,  0.0917],\n",
      "          [ 0.1853, -0.0286,  0.0230],\n",
      "          [ 0.0769,  0.0624, -0.0412]],\n",
      "\n",
      "         [[-0.1652,  0.1154, -0.0791],\n",
      "          [-0.1138, -0.1212,  0.0235],\n",
      "          [-0.0745, -0.0464,  0.1919]]],\n",
      "\n",
      "\n",
      "        [[[-0.0378,  0.1040, -0.1761],\n",
      "          [ 0.1199, -0.0384,  0.1365],\n",
      "          [ 0.0758,  0.1288,  0.1750]],\n",
      "\n",
      "         [[-0.0106,  0.0752, -0.0695],\n",
      "          [-0.0517, -0.1113,  0.0177],\n",
      "          [ 0.0389,  0.0801, -0.0945]],\n",
      "\n",
      "         [[ 0.0186,  0.1384, -0.1208],\n",
      "          [ 0.1755,  0.0922, -0.1425],\n",
      "          [-0.1828,  0.0370, -0.1176]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1864, -0.1232,  0.0591],\n",
      "          [ 0.1801,  0.1279, -0.1455],\n",
      "          [ 0.0368,  0.1479, -0.0300]],\n",
      "\n",
      "         [[-0.1000, -0.0924,  0.0952],\n",
      "          [-0.1686, -0.0380, -0.1898],\n",
      "          [ 0.0862,  0.0627, -0.0801]],\n",
      "\n",
      "         [[-0.0030,  0.1453,  0.1672],\n",
      "          [-0.1763, -0.1490, -0.0303],\n",
      "          [ 0.0205, -0.1029,  0.0309]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0423, -0.0553,  0.1536],\n",
      "          [-0.0274, -0.0751,  0.1613],\n",
      "          [-0.0629,  0.0055,  0.1866]],\n",
      "\n",
      "         [[-0.1306,  0.0389,  0.1847],\n",
      "          [-0.1763,  0.1502,  0.0768],\n",
      "          [ 0.0467,  0.1896, -0.1200]],\n",
      "\n",
      "         [[ 0.1466,  0.1684, -0.0439],\n",
      "          [-0.0035,  0.1809,  0.1565],\n",
      "          [ 0.0895,  0.0295,  0.0797]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0347, -0.1905, -0.1673],\n",
      "          [-0.0519,  0.0672, -0.1554],\n",
      "          [-0.1373, -0.0191, -0.1503]],\n",
      "\n",
      "         [[-0.1051,  0.0074, -0.0918],\n",
      "          [ 0.0676, -0.0201, -0.0987],\n",
      "          [ 0.1757, -0.0498,  0.0378]],\n",
      "\n",
      "         [[ 0.1789, -0.1493, -0.0636],\n",
      "          [-0.0768, -0.0358,  0.0247],\n",
      "          [-0.0581, -0.1259,  0.1470]]],\n",
      "\n",
      "\n",
      "        [[[-0.0996,  0.1374,  0.0153],\n",
      "          [-0.1777, -0.1776,  0.1913],\n",
      "          [ 0.0077, -0.1472,  0.0140]],\n",
      "\n",
      "         [[-0.1541, -0.1443,  0.1303],\n",
      "          [ 0.0807, -0.0986,  0.1643],\n",
      "          [-0.0614,  0.0312, -0.1742]],\n",
      "\n",
      "         [[ 0.0759, -0.0294,  0.1205],\n",
      "          [-0.0753,  0.0061, -0.0610],\n",
      "          [ 0.1539,  0.0635,  0.1396]]],\n",
      "\n",
      "\n",
      "        [[[-0.0565,  0.0748, -0.0563],\n",
      "          [-0.0404,  0.0368, -0.0036],\n",
      "          [ 0.0525,  0.1249,  0.0726]],\n",
      "\n",
      "         [[ 0.1260, -0.0764,  0.0992],\n",
      "          [-0.1627,  0.0258,  0.1835],\n",
      "          [-0.1550, -0.1646,  0.0958]],\n",
      "\n",
      "         [[ 0.0011, -0.0360, -0.0395],\n",
      "          [ 0.1507, -0.1302, -0.0848],\n",
      "          [ 0.1791, -0.0300,  0.0845]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0990, -0.1868,  0.0875],\n",
      "          [ 0.0713,  0.0110,  0.1119],\n",
      "          [-0.0467,  0.0977, -0.1488]],\n",
      "\n",
      "         [[ 0.1712, -0.0508, -0.1620],\n",
      "          [ 0.0502, -0.1612,  0.0991],\n",
      "          [ 0.0553, -0.1015, -0.0230]],\n",
      "\n",
      "         [[ 0.1102,  0.0910,  0.1278],\n",
      "          [ 0.1639,  0.1580,  0.0721],\n",
      "          [-0.0358, -0.0603,  0.0131]]],\n",
      "\n",
      "\n",
      "        [[[-0.0636, -0.0544,  0.0126],\n",
      "          [-0.1428, -0.1368, -0.0826],\n",
      "          [-0.1335, -0.0311,  0.1864]],\n",
      "\n",
      "         [[-0.1860,  0.1819,  0.1441],\n",
      "          [-0.0473,  0.1264, -0.0917],\n",
      "          [ 0.1490, -0.1145,  0.1359]],\n",
      "\n",
      "         [[-0.1520,  0.1886, -0.0187],\n",
      "          [ 0.0095,  0.1889,  0.1455],\n",
      "          [ 0.0744, -0.1574,  0.0835]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1845, -0.0179,  0.1020],\n",
      "          [ 0.0755, -0.0886, -0.0160],\n",
      "          [ 0.0693,  0.0131,  0.0771]],\n",
      "\n",
      "         [[ 0.0840,  0.1519, -0.0218],\n",
      "          [ 0.0612,  0.0047,  0.0578],\n",
      "          [-0.0769, -0.1015,  0.0972]],\n",
      "\n",
      "         [[-0.1858,  0.1786,  0.0611],\n",
      "          [-0.1103, -0.0078, -0.0548],\n",
      "          [-0.0670,  0.0973,  0.0781]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1298, -0.0634,  0.1361],\n",
      "          [-0.1574, -0.0453,  0.1755],\n",
      "          [ 0.0981,  0.0477,  0.0491]],\n",
      "\n",
      "         [[ 0.0071,  0.0932, -0.1267],\n",
      "          [-0.1443, -0.1018,  0.0856],\n",
      "          [ 0.0226, -0.1468, -0.0022]],\n",
      "\n",
      "         [[-0.0016, -0.1282,  0.0983],\n",
      "          [ 0.1499,  0.0115, -0.1813],\n",
      "          [-0.0267, -0.1623,  0.1189]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1686, -0.0612,  0.1018],\n",
      "          [-0.1339,  0.0460,  0.0090],\n",
      "          [ 0.1770, -0.1264, -0.0944]],\n",
      "\n",
      "         [[ 0.1406,  0.0357, -0.0156],\n",
      "          [-0.1619, -0.0891,  0.0882],\n",
      "          [-0.1699, -0.1060,  0.1688]],\n",
      "\n",
      "         [[ 0.0921,  0.0928, -0.0427],\n",
      "          [-0.0233,  0.0012,  0.0686],\n",
      "          [-0.0591,  0.1703,  0.1208]]],\n",
      "\n",
      "\n",
      "        [[[-0.1608,  0.1324, -0.1873],\n",
      "          [-0.0275, -0.0444,  0.0019],\n",
      "          [ 0.1637,  0.1089,  0.0090]],\n",
      "\n",
      "         [[ 0.1171, -0.0688, -0.1717],\n",
      "          [ 0.0176,  0.0226, -0.0219],\n",
      "          [-0.1004, -0.0113,  0.1520]],\n",
      "\n",
      "         [[-0.0404, -0.0087, -0.0036],\n",
      "          [-0.1503, -0.0600, -0.0458],\n",
      "          [-0.1027, -0.1650,  0.1540]]],\n",
      "\n",
      "\n",
      "        [[[-0.0450, -0.0178,  0.1405],\n",
      "          [-0.0229,  0.0078,  0.1059],\n",
      "          [ 0.0180, -0.1595,  0.0788]],\n",
      "\n",
      "         [[ 0.0321,  0.1468, -0.1756],\n",
      "          [-0.0331, -0.1427, -0.0791],\n",
      "          [ 0.1100,  0.0916,  0.1641]],\n",
      "\n",
      "         [[-0.1417, -0.1886,  0.0359],\n",
      "          [-0.0660,  0.0535,  0.1196],\n",
      "          [-0.1587,  0.0576, -0.0820]]],\n",
      "\n",
      "\n",
      "        [[[-0.0462,  0.1724,  0.1216],\n",
      "          [ 0.0572, -0.1760, -0.0223],\n",
      "          [-0.0065,  0.0434, -0.0972]],\n",
      "\n",
      "         [[ 0.0697,  0.1564, -0.0213],\n",
      "          [-0.1414,  0.0537, -0.0563],\n",
      "          [ 0.0949,  0.1752,  0.0575]],\n",
      "\n",
      "         [[ 0.0421, -0.1848, -0.1397],\n",
      "          [-0.0541, -0.1243, -0.0447],\n",
      "          [-0.1801,  0.0923,  0.0398]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0390,  0.1606,  0.0355],\n",
      "          [ 0.1328, -0.1263,  0.0862],\n",
      "          [-0.0956, -0.0441,  0.0828]],\n",
      "\n",
      "         [[-0.1391,  0.0770,  0.0900],\n",
      "          [-0.0903, -0.0411,  0.1823],\n",
      "          [-0.1728,  0.1713, -0.0939]],\n",
      "\n",
      "         [[-0.0138, -0.0958,  0.0722],\n",
      "          [-0.0692, -0.0470,  0.0642],\n",
      "          [-0.1301, -0.0501,  0.0241]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0167, -0.0565, -0.1132,  0.0184, -0.1875, -0.0006, -0.0077, -0.0912,\n",
      "         0.0936, -0.0718,  0.1531,  0.0785,  0.1058,  0.0345,  0.1512,  0.0915],\n",
      "       requires_grad=True)\n",
      "\n",
      "Forma de los datos y datos de salida:\n",
      "torch.Size([1, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Creación de una capa Conv2D \n",
    "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Crea algunos datos de entrada\n",
    "# Tensor de entrada: (batch_size, nchannels, height, width)\n",
    "input_data = torch.randn(1, 3, 32, 32)  \n",
    "\n",
    "# Ejecuta la capa convolucional sobre los datos de entrada\n",
    "output_data = conv_layer(input_data)\n",
    "\n",
    "print(\"Forma de los datos y datos de entrada:\")\n",
    "print(input_data.shape)\n",
    "print(input_data)\n",
    "print(\"Capa convolucional (pesos y bias):\")\n",
    "print(conv_layer.weight)\n",
    "print(conv_layer.bias)\n",
    "print(\"\\nForma de los datos y datos de salida:\")\n",
    "print(output_data.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a hacer algunas transformaciones y operaciones comunes sobre capas convolucionales. Para ello empezaremos con una capa e iremos aplicando todas esas operaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[[ 1.15, -1.83,  0.25,  1.32],\n",
      "          [-1.93, -0.09,  0.64, -2.10],\n",
      "          [ 0.17, -1.73, -0.17,  0.71],\n",
      "          [-0.27,  0.43,  0.33,  1.63]],\n",
      "\n",
      "         [[ 1.59,  2.00,  0.27, -0.09],\n",
      "          [-1.24, -0.79,  0.26,  0.19],\n",
      "          [ 0.53, -0.16, -1.39, -1.27],\n",
      "          [ 1.13, -1.13, -1.39,  0.96]],\n",
      "\n",
      "         [[-0.07,  0.68,  0.12, -0.40],\n",
      "          [-1.19, -1.09,  0.78,  1.02],\n",
      "          [-0.83, -1.31, -0.06, -1.53],\n",
      "          [ 0.99, -1.42, -0.78, -2.51]]]])\n",
      "\n",
      "MaxPool2d:\n",
      "tensor([[[[ 1.15,  1.32],\n",
      "          [ 0.43,  1.63]],\n",
      "\n",
      "         [[ 2.00,  0.27],\n",
      "          [ 1.13,  0.96]],\n",
      "\n",
      "         [[ 0.68,  1.02],\n",
      "          [ 0.99, -0.06]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.set_printoptions(precision=2)\n",
    "# Creación de una capa Conv2D \n",
    "tensor=torch.randn(1,3,4,4)\n",
    "print(\"Original tensor:\")\n",
    "print(tensor)\n",
    "maxpooled2d=torch.nn.MaxPool2d(2, stride=2)\n",
    "print(\"\\nMaxPool2d:\")\n",
    "print(maxpooled2d(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[[ 1.42, -0.07,  1.05, -0.53],\n",
      "          [-0.53,  0.81,  0.39,  0.67],\n",
      "          [ 0.52,  1.00, -1.14, -0.81],\n",
      "          [-0.97, -0.12, -0.51, -1.80]],\n",
      "\n",
      "         [[-0.20, -2.37,  0.29,  0.29],\n",
      "          [ 1.13,  0.04, -0.88, -1.91],\n",
      "          [-0.78, -0.12, -0.38, -1.08],\n",
      "          [ 0.11, -0.48, -0.91, -1.97]],\n",
      "\n",
      "         [[ 2.00, -1.18, -0.46,  0.51],\n",
      "          [-0.24, -0.45,  0.19,  0.37],\n",
      "          [ 0.83,  0.03, -0.80, -1.64],\n",
      "          [ 0.70,  1.81,  1.19, -0.50]]]])\n",
      "\n",
      "ZeroPadded:\n",
      "tensor([[[[ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
      "          [ 0.00,  1.42, -0.07,  1.05, -0.53,  0.00],\n",
      "          [ 0.00, -0.53,  0.81,  0.39,  0.67,  0.00],\n",
      "          [ 0.00,  0.52,  1.00, -1.14, -0.81,  0.00],\n",
      "          [ 0.00, -0.97, -0.12, -0.51, -1.80,  0.00],\n",
      "          [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00]],\n",
      "\n",
      "         [[ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
      "          [ 0.00, -0.20, -2.37,  0.29,  0.29,  0.00],\n",
      "          [ 0.00,  1.13,  0.04, -0.88, -1.91,  0.00],\n",
      "          [ 0.00, -0.78, -0.12, -0.38, -1.08,  0.00],\n",
      "          [ 0.00,  0.11, -0.48, -0.91, -1.97,  0.00],\n",
      "          [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00]],\n",
      "\n",
      "         [[ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
      "          [ 0.00,  2.00, -1.18, -0.46,  0.51,  0.00],\n",
      "          [ 0.00, -0.24, -0.45,  0.19,  0.37,  0.00],\n",
      "          [ 0.00,  0.83,  0.03, -0.80, -1.64,  0.00],\n",
      "          [ 0.00,  0.70,  1.81,  1.19, -0.50,  0.00],\n",
      "          [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.set_printoptions(precision=2)\n",
    "# Creación de una capa Conv2D \n",
    "tensor=torch.randn(1,3,4,4)\n",
    "print(\"Original tensor:\")\n",
    "print(tensor)\n",
    "padding=torch.nn.ZeroPad2d(1)\n",
    "print(\"\\nZeroPadded:\")\n",
    "print(padding(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[[-1.39,  1.09,  0.48, -1.50],\n",
      "          [-1.80, -0.42, -0.44,  1.92],\n",
      "          [-1.22, -0.64, -0.81, -2.22],\n",
      "          [ 1.16, -0.51,  1.68, -0.84]],\n",
      "\n",
      "         [[-2.44, -0.05,  0.04, -0.79],\n",
      "          [-0.51, -1.95,  0.54, -0.50],\n",
      "          [ 0.84,  0.38, -2.00, -0.90],\n",
      "          [ 0.03,  0.50, -0.58,  0.82]],\n",
      "\n",
      "         [[ 0.40, -0.17, -2.18, -0.24],\n",
      "          [ 1.63,  0.79,  0.52,  1.82],\n",
      "          [-0.06, -0.60,  0.96, -0.58],\n",
      "          [-1.39,  0.30, -0.48, -0.78]]]])\n",
      "\n",
      "Normalized:\n",
      "tensor([[[[-0.86,  1.18,  0.67, -0.95],\n",
      "          [-1.20, -0.06, -0.08,  1.86],\n",
      "          [-0.73, -0.25, -0.38, -1.54],\n",
      "          [ 1.24, -0.14,  1.66, -0.41]],\n",
      "\n",
      "         [[-2.07,  0.37,  0.46, -0.39],\n",
      "          [-0.10, -1.57,  0.97, -0.09],\n",
      "          [ 1.27,  0.81, -1.62, -0.50],\n",
      "          [ 0.45,  0.92, -0.17,  1.25]],\n",
      "\n",
      "         [[ 0.40, -0.16, -2.15, -0.23],\n",
      "          [ 1.62,  0.78,  0.52,  1.80],\n",
      "          [-0.05, -0.59,  0.95, -0.57],\n",
      "          [-1.37,  0.30, -0.47, -0.77]]]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Creación de una capa Conv2D \n",
    "torch.set_printoptions(precision=2)\n",
    "tensor=torch.randn(1,3,4,4)\n",
    "print(\"Original tensor:\")\n",
    "print(tensor)\n",
    "normalization=torch.nn.BatchNorm2d(3)\n",
    "print(\"\\nNormalized:\")\n",
    "print(normalization(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[[ 0.04,  0.97,  0.79, -1.50],\n",
      "          [-1.00,  0.36,  0.96, -1.34],\n",
      "          [-0.43,  0.01,  0.76,  0.90],\n",
      "          [-0.08,  0.49, -0.62,  0.23]],\n",
      "\n",
      "         [[ 0.70, -0.64, -0.20,  0.51],\n",
      "          [-0.10, -0.58,  0.84,  0.41],\n",
      "          [ 0.41,  1.31,  0.28,  1.23],\n",
      "          [-1.67,  0.42, -1.62,  1.19]],\n",
      "\n",
      "         [[ 0.83, -1.10, -0.54,  0.38],\n",
      "          [-2.21, -0.35,  1.04,  0.59],\n",
      "          [-0.06,  0.65, -0.09, -0.90],\n",
      "          [ 0.76,  0.61, -1.43,  1.07]]]])\n",
      "\n",
      "Droppedout:\n",
      "tensor([[[[ 0.07,  1.95,  1.57, -3.00],\n",
      "          [-1.99,  0.71,  1.92, -2.68],\n",
      "          [-0.86,  0.03,  1.52,  1.80],\n",
      "          [-0.15,  0.99, -1.23,  0.45]],\n",
      "\n",
      "         [[ 0.00, -0.00, -0.00,  0.00],\n",
      "          [-0.00, -0.00,  0.00,  0.00],\n",
      "          [ 0.00,  0.00,  0.00,  0.00],\n",
      "          [-0.00,  0.00, -0.00,  0.00]],\n",
      "\n",
      "         [[ 0.00, -0.00, -0.00,  0.00],\n",
      "          [-0.00, -0.00,  0.00,  0.00],\n",
      "          [-0.00,  0.00, -0.00, -0.00],\n",
      "          [ 0.00,  0.00, -0.00,  0.00]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Creación de una capa Conv2D \n",
    "torch.set_printoptions(precision=2)\n",
    "tensor=torch.randn(1,3,4,4)\n",
    "print(\"Original tensor:\")\n",
    "print(tensor)\n",
    "dropout=torch.nn.Dropout2d(0.5)\n",
    "print(\"\\nDroppedout:\")\n",
    "print(dropout(tensor))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "\n",
    "Observa el siguiente código en el que creamos una red convolucional para clasificar imágenes del dataset CIFAR-10. En el código faltan la definición de la arquitectura del modelo, debería ser hecha a base de capas *Linear* y *Conv2D* y la definición de la pasadad Forward. Completa esta información\n",
    "\n",
    "[1] CIFAR-10 dataset: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Creación de un transformador que normaliza los datos\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# Descarga del dataset CIFAR-10: conjunto de entrenamiento\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "# Creación de un dataloader para el dataset CIFAR-10: conjunto de entrenamiento\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "# Descarga del dataset CIFAR-10: conjunto de test\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "# Creación de un dataloader para el dataset CIFAR-10: conjunto de test\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "# Definimos las clases del dataset CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "# Crear un modelo de red neuronal\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Aquí debes definir las capas de tu red neuronal\n",
    "        # Definimos una capa convolucional con 3 canales de entrada, 6 canales de salida, kernel de 5x5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        # Definimos una capa de MaxPooling (2,2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Definimos una capa convolucional con 6 canales de entrada, 16 canales de salida, kernel de 5x5\n",
    "        # ESCRIBE TU CÓDIGO AQUÍ\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Definimos una capa lineal con 16*5*5 entradas y 120 salidas\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # Definimos una capa lineal con 120 entradas y 84 salidas\n",
    "        # ESCRIBE TU CÓDIGO AQUÍ\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # Definimos una capa lineal con 84 entradas y 10 salidas\n",
    "        # ESCRIBE TU CÓDIGO AQUÍ\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Aquí debemos definir el paso forward\n",
    "        # Aplicamos la función de activación ReLU a la salida de la primera capa convolucional\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # Aplicamos la función de activación ReLU a la salida de la segunda capa convolucional\n",
    "        # ESCRIBE TU CÓDIGO AQUÍ\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Aplanamos la salida de la segunda capa convolucional usando la función view\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        # Aplicamos la función de activación ReLU a la salida de la primera capa lineal\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Aplicamos la función de activación ReLU a la salida de la segunda capa lineal\n",
    "        # ESCRIBE TU CÓDIGO AQUÍ\n",
    "        x=F.relu(self.fc2(x))\n",
    "        # Aplicamos la tercera capa lineal\n",
    "        # ESCRIBE TU CÓDIGO AQUÍ\n",
    "        x=F.relu(self.fc3(x))   \n",
    "        return x\n",
    "\n",
    "# Inicializar el modelo\n",
    "net = Net()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación definimos el bucle de entrenamiento. Aquí no tenemos que hacer nada, se incluye a efectos de poder probar la red definida anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.203\n",
      "[1,  4000] loss: 1.905\n",
      "[1,  6000] loss: 1.686\n",
      "[1,  8000] loss: 1.569\n",
      "[1, 10000] loss: 1.478\n",
      "[1, 12000] loss: 1.473\n",
      "[2,  2000] loss: 1.393\n",
      "[2,  4000] loss: 1.376\n",
      "[2,  6000] loss: 1.335\n",
      "[2,  8000] loss: 1.290\n",
      "[2, 10000] loss: 1.282\n",
      "[2, 12000] loss: 1.258\n",
      "[3,  2000] loss: 1.176\n",
      "[3,  4000] loss: 1.183\n",
      "[3,  6000] loss: 1.179\n",
      "[3,  8000] loss: 1.158\n",
      "[3, 10000] loss: 1.160\n",
      "[3, 12000] loss: 1.173\n",
      "[4,  2000] loss: 1.074\n",
      "[4,  4000] loss: 1.093\n",
      "[4,  6000] loss: 1.072\n",
      "[4,  8000] loss: 1.073\n",
      "[4, 10000] loss: 1.058\n",
      "[4, 12000] loss: 1.067\n",
      "[5,  2000] loss: 0.996\n",
      "[5,  4000] loss: 0.988\n",
      "[5,  6000] loss: 0.997\n",
      "[5,  8000] loss: 1.001\n",
      "[5, 10000] loss: 1.011\n",
      "[5, 12000] loss: 1.030\n",
      "[6,  2000] loss: 0.911\n",
      "[6,  4000] loss: 0.933\n",
      "[6,  6000] loss: 0.949\n",
      "[6,  8000] loss: 0.936\n",
      "[6, 10000] loss: 0.967\n",
      "[6, 12000] loss: 0.953\n",
      "[7,  2000] loss: 0.868\n",
      "[7,  4000] loss: 0.887\n",
      "[7,  6000] loss: 0.890\n",
      "[7,  8000] loss: 0.908\n",
      "[7, 10000] loss: 0.899\n",
      "[7, 12000] loss: 0.910\n",
      "[8,  2000] loss: 0.803\n",
      "[8,  4000] loss: 0.844\n",
      "[8,  6000] loss: 0.852\n",
      "[8,  8000] loss: 0.863\n",
      "[8, 10000] loss: 0.858\n",
      "[8, 12000] loss: 0.891\n",
      "[9,  2000] loss: 0.764\n",
      "[9,  4000] loss: 0.811\n",
      "[9,  6000] loss: 0.828\n",
      "[9,  8000] loss: 0.808\n",
      "[9, 10000] loss: 0.857\n",
      "[9, 12000] loss: 0.856\n",
      "[10,  2000] loss: 0.736\n",
      "[10,  4000] loss: 0.769\n",
      "[10,  6000] loss: 0.803\n",
      "[10,  8000] loss: 0.785\n",
      "[10, 10000] loss: 0.803\n",
      "[10, 12000] loss: 0.821\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Definición de la función de pérdida y el optimizador\n",
    "# Loss function (Cross-Entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (SGD)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(10):  # Número de epochs\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # coge las entradas: es un array de [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # reinicia los gradientes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Imprime estadísticas\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # Imprime la pérdida cada 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos calcular la precición del modelo. Tampoco aquí debemos hacer nada en el ejercicio. Se incluye el código a efectos de probar nuestro modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la red sobre las 1000 imágenes de prueba: 64 %\n"
     ]
    }
   ],
   "source": [
    "# Prueba el modelo sobre el conjunto de test\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Precisión de la red sobre las 1000 imágenes de prueba: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
