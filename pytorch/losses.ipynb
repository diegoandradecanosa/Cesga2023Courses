{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de pérdida\n",
    "\n",
    "La función de pérdida es un componente fundamental del proceso de entrenamiento de una RN. Mide la distancia entre la salida obtenida por el modelo (para una determinada entrada) y la salida deseada. Este valor es utilizado por el optimizador del modelo para realizar el cálculo de los gradientes del modelo, al final de cada *step* del proceso de entrenamiento.\n",
    "\n",
    "Existen dos categorías de funciones de pérdida:\n",
    "\n",
    "- Regresión: Son útiles para procesos de optimización cuyo objetivo es predecir un valor numérico en un intervalo continuo (ej. la probabilidad de lluvia).\n",
    "- Clasificación: Son útiles para tareas en las que el objetivo es predecir un valor entre varios posibles valores categóricos (ej. la especie de un animal que aparece en una fotografía).\n",
    "\n",
    "En Pytorch, existen implementaciones para varias funciones de optimización populares. Antes de ver algunos ejemplos, veamos cómo podemos realizar el cálculo de una función de pérdida sencilla utilizando operaciones básicas sobre tensores.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.14000000059604645\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Genera dos salidas de la red neuronal sintéticas\n",
    "output1 = torch.tensor([1.0, 2.0, 3.0, 4.0])  # Sample output 1\n",
    "output2 = torch.tensor([0.5, 1.5, 2.5, 3.5])  # Sample output 2\n",
    "\n",
    "# Genera un vector de valores objetivo (ground truth)\n",
    "target = torch.tensor([0.8, 1.7, 2.9, 3.8])\n",
    "\n",
    "# Calcula la diferencia al cuadrado entre las salidas y los valores objetivo\n",
    "squared_diff1 = torch.pow(output1 - target, 2)\n",
    "squared_diff2 = torch.pow(output2 - target, 2)\n",
    "\n",
    "# Calcula el error cuadrático medio (MSE) entre las salidas y los valores objetivo\n",
    "loss = torch.mean(squared_diff1) + torch.mean(squared_diff2)\n",
    "print(\"MSE Loss:\", loss.item())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exite una función en Pytorch que implementa el MSE, la cual se puede utilizar de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.14000000059604645\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "output1 = torch.tensor([1.0, 2.0, 3.0, 4.0])  # Salida de ejemplo 1\n",
    "output2 = torch.tensor([0.5, 1.5, 2.5, 3.5])  # Salida de ejemplo 2\n",
    "target = torch.tensor([0.8, 1.7, 2.9, 3.8])\n",
    "\n",
    "# Calcula el error cuadrático medio (MSE) entre las salidas y los valores objetivo usando la función MSELoss\n",
    "criterion = torch.nn.MSELoss()\n",
    "loss = criterion(output1, target) + criterion(output2, target)\n",
    "print(\"MSE Loss:\", loss.item())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De aquí en adelante vamos a usar ejemplos en los que siempre se usan funciones que implementan cálculos de funciones de pérdida populares en Pytorch. \n",
    "\n",
    "Siguiendo, dentro de la categoría de funciones de pérdida regresivas, vemos ahora un ejemplo, basado en el miso caso de uso de la función de pérdida L1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Loss: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Calcula el error cuadrático medio (L1) entre las salidas y los valores objetivo usando la función L1Loss\n",
    "criterion = torch.nn.L1Loss()\n",
    "loss = criterion(output1, target) + criterion(output2, target)\n",
    "print(\"L1 Loss:\", loss.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso el valor de pérdida obtenido es mucho más alto. La diferencia es que MSELoss usaba el cuadrado de las diferencias, mientras L1Loss utiliza para su cálculo el valor absoluto de la diferencia.\n",
    "\n",
    "Veamos ahora, una reproducción del mismo ejemplo, utilizando la función de pérdida regresiva Mean Bias Error (MBE). En este caso, no hay ninguna implementación para Pytorch, así que utilizamos una implementación hecha por nosotros mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2000, 0.3000, 0.1000, 0.2000])\n",
      "tensor([-0.3000, -0.2000, -0.4000, -0.3000])\n",
      "MBE Loss: -0.05000001937150955\n"
     ]
    }
   ],
   "source": [
    "# Calcula el Mean Bias Error (MBE) entre las salidas y los valores objetivo \n",
    "diff1 = output1 - target\n",
    "diff2 = output2 - target\n",
    "print(diff1)\n",
    "print(diff2)\n",
    "loss = torch.mean(diff1) + torch.mean(diff2)\n",
    "print(\"MBE Loss:\", loss.item()/2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad\n",
    "\n",
    "Dadas las salidas reales y desadas anteriores: *outpu1*, *output2*, *target*, calcula una función de pérdida con la siguiente formulación.\n",
    "\n",
    "FPP = ∑ |output1 - target| + ∑ |output2 - target|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pon tu código aquí"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de pérdida categóricas\n",
    "\n",
    "Vamos a explorar ahora varios ejemplos de funciones de pérdida categóricas. En este caso, se abordan problemas en los que la salida del modelo es un vector de probabilidades. Cada elemento de dicho vector, mide la probabilidad de que la entrada se clasifique en la categoría correspondiente. \n",
    "\n",
    "Un ejemplo sencillo, sería una RN para la cual se predice el número contenido en imágenes del conjunto de datos CIFAR-10. La salida es un vector de 10 elementos, donde el primer elemento contiene la probabilidad de que el número en la imagen sea un 0, el segundo elemento la probabilidad de que sea un 1, etc...\n",
    "\n",
    "Las funciones de pérdida de este tipo deben capturar la diferencia entre la clase prevista y las probabilidades contenidas en vector de salida obtenido de la inferencia del modelo. La clase prevista asigna un 100% de probabilidad a la clase correcta y 0 a todas las demás, por lo tanto, las funciones de pérdida deben capturar cuánto se alejan las probabilidades del modelo de esta predicción perfecta.\n",
    "\n",
    "Las funciones de pérdida categóricas tratan de capturar esta diferencia. Una de ellas es *SVM Loss* y vemos ahora un ejemplo sobre esta función cuya fórmula simplificada es SVM Loss = ∑ max(0, 1 - y_i * f(x_i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Loss: 0.9149999618530273\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Predicción y objetivo de ejemplo\n",
    "predictions = torch.tensor([0.85, 0.12, 0.08, 0.01, 0, 0, 0.23, 0, 0.4 ,0.2]) \n",
    "targets = torch.tensor([1, 0, 0, 0, 0, 0, 0, 0, 0 ,0])\n",
    "\n",
    "# Cálculo de la pérdida SVM\n",
    "loss = torch.mean(torch.max(torch.zeros_like(targets), 1 - targets * predictions))\n",
    "print(\"SVM Loss:\", loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
