{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard con Pytorch\n",
    "\n",
    "Tensorboard es una herramientas de visualización asociada al ecosistema de TensorFlow. Es tan popular, que también está soportada en Pytorch y su uso es habitual. Permite visualizar:\n",
    "\n",
    "- Métricas como la *loss* o la *accuracy*.\n",
    "- El grafo que representa la arquitectura del modelo\n",
    "- La evolución en tiempo real de los histogramas de pesos y *bias*\n",
    "- Información de rendmimiento computacional: uso de GPU, línea de tiempo de la ejecución, uso de memoria, etc...\n",
    "\n",
    "Vamos a ver un ejemplo en el que usamos una red convolucional sencilla para realizar una operación de clasificación sobre el conjunto de datos MNIST. En este conjunto de datos, tenemos que identificar en una imagen el tipo de prenda que muestran. Empezamos cargando el conjunto de datos utilizando el módulo torchvision.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:06<00:00, 4090682.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 552485.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:00<00:00, 9029693.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 14728701.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, realizamos la definición de la red convolucional que vamos a entrenar y la instanciamos. La red está compuesta por los siguientes elementos:\n",
    "- Las imágenes de este data set tienen un único canal (b/n) y un tamaño de 28x28 píxeles.\n",
    "- Una capa Convolucional.\n",
    "- Una capa MaxPool2d.\n",
    "- y Tres capas lineales totalmente conectadas. Terminando en una salida compuest por 10 probabilidades, cada una asociada a un tipo de prenda.\n",
    "\n",
    "Luego, definimos la función de pérdida (*Cross-Entropy-Loss) y el optimizador (SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a empezar con la configuración de TensorBoard, creando un *SummaryWriter* que lleva asociada una ubicación en el sistema de ficheros, donde vamos a escribir los datos necesarias para luego utilizar TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorboard in /home/diegoandrade/.local/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/diegoandrade/.local/lib/python3.10/site-packages (from tensorboard) (1.56.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/diegoandrade/.local/lib/python3.10/site-packages (from tensorboard) (2.28.1)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/diegoandrade/.local/lib/python3.10/site-packages (from tensorboard) (4.23.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/diegoandrade/.local/lib/python3.10/site-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard) (59.6.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/diegoandrade/.local/lib/python3.10/site-packages (from tensorboard) (2.2.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/diegoandrade/.local/lib/python3.10/site-packages (from tensorboard) (2.20.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/diegoandrade/.local/lib/python3.10/site-packages (from tensorboard) (0.7.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/diegoandrade/.local/lib/python3.10/site-packages (from tensorboard) (3.4.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/diegoandrade/.local/lib/python3.10/site-packages (from tensorboard) (1.23.5)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/diegoandrade/.local/lib/python3.10/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/diegoandrade/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/diegoandrade/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/diegoandrade/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.26.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/diegoandrade/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/diegoandrade/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/diegoandrade/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/diegoandrade/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver, en primer lugar, cómo escribir una rejilla *grid* de imágenes aleatorias de nuestro conjunto de datos, para poder visualizarlas desde TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependiendo de cómo estemos usando este notebook, vamos a tener distintas formas de utilizar TensorBoard. Una que debería funciona en prácticamente cualquier entorno, es en un terminar ejecutar el siguiente comando.\n",
    "\n",
    "tensorboard --logdir=runs\n",
    "\n",
    "Otra cosa que podemos hacer con TensorBoard es visualizar la arquitectura del modelo. Para ello, debemos ejecutar el siguiente código\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra herramienta de visualización que resulta muy útil son los *Projectors*. Estos generan una representación de baja dimensionalidad de datos de alta dimensionalidad. Para ello, utilizaremos el método *add_embedding*. Veamos un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En TensorBoard, deberíamos tener una pestaña más que contiene la información generada por el Proyector.\n",
    "\n",
    "A continuación, vamos a ver otro ejemplo, en este caso de cómo generar información sobre la evolución de la función de pérdida (*loss*), y además de una vista de las predicciones que está generando el modelo *plot_classes_pred*. Para ello, tenemos que definir un par de funciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer uso de la función anterior, *plot_classes_pred* tenemos que utilizarla en el contexto de un bucle de entrenamiento. Veamos cómo se integra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si abrimos Tensorboard, y recargamos, veremos una nueva pestaña *Scalars* donde podemos visualizar la evolución del valor de la función de pérdida con el tiempo.\n",
    "\n",
    "En la pestaña *Images*, después de recargar su contenido, veremos una versión de la imagen que muestra ejemplos aleatorios del conjunto de entrenamiento, con las etiquetas predichas, la probabilidad asociada y las etiquetas esperadas.\n",
    "\n",
    "\n",
    "Una última cosa que vamos a hacer es generar *PrecisionRecallCurves* para evaluar la precisión de nuestro clasificador. \n",
    "Esta métrica muestra el balance entre dos métricas para un clasificador:\n",
    "\n",
    "- *Precision*: Indica la precisión del modelo y se calcula como *true positives*/*true positives*+*false positives*\n",
    "- *Recall*: Indica el grado de completitud y se calcula como *true positives*/*true positives*+*false negatives*\n",
    "\n",
    "Como siempre, primero, ejecutamos el código Python que genera dicha información. Luego, iremos a Tensorboard a ver los resultados en una pestaña nueva que se generará llamada *PR Curves*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_label = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "\n",
    "Utilizando como el base, el código resultante del ejercicio al final del notebook *optimizers.ipynb*, haz los cambios pertinentes para registrar la figura de la comparativa de la loss_function entre los 3 optimizadores. Comprueba luego que puedes visualizarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch 1, Loss: 0.05794943155527115\n",
      "Epoch 1, Metrics: {'MulticlassHammingDistance': tensor(0.5833), 'MulticlassF1Score': tensor(0.4167)}\n",
      "Epoch 2, Loss: 0.050726215015351774\n",
      "Epoch 2, Metrics: {'MulticlassHammingDistance': tensor(0.4583), 'MulticlassF1Score': tensor(0.5417)}\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import HammingDistance, F1Score, MetricCollection\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/cifar10_experiment_1')\n",
    "\n",
    "# Inicializamos el modelo, la métrica y el optimizador\n",
    "metrics = MetricCollection([HammingDistance(task='multiclass', num_classes=10), F1Score(task='multiclass',num_classes=10, threshold=0.5)])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Define the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define the loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the training function\n",
    "def train(net, trainloader, optimizer, num_epochs=2):\n",
    "    loss_values = []\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # save losses to plot later\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                loss_values.append(running_loss / 2000)\n",
    "                running_loss = 0.0\n",
    "                metrics(torch.argmax(outputs,dim=1), labels)\n",
    "                 # ...log the running loss\n",
    "                writer.add_scalar('training loss',\n",
    "                            running_loss / 2000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}\")\n",
    "        print(f\"Epoch {epoch+1}, Metrics: {metrics.compute()}\")\n",
    "        # Reinicializamos la métrica para la siguiente época\n",
    "        metrics.reset()\n",
    "\n",
    "    return loss_values\n",
    "\n",
    "# SGDs\n",
    "net_SGD = Net()\n",
    "optimizer_SGD = optim.SGD(net_SGD.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_SGD = train(net_SGD, trainloader, optimizer_SGD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
