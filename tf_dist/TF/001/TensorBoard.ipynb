{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23558d8",
   "metadata": {},
   "source": [
    "Fuente: https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf110aff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "os.system('export LD_LIBRARY_PATH=$STORE/mytf/lib/python3.9/site-packages/nvidia/cuda_cupti/lib/:$LD_LIBRARY_PATH')\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "592406e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-16c2dc9b9c4e27ed\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-16c2dc9b9c4e27ed\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6010;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "!kill 538063\n",
    "%tensorboard --logdir=./logs --port=6010 --host=0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "112ca410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 09:39:14.061444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:98:00.0, compute capability: 7.5\n",
      "2023-11-02 09:39:14.094202: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-11-02 09:39:14.094287: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-11-02 09:39:14.094333: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-11-02 09:39:14.094366: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:186] cuptiSubscribe: ignored due to a previous error.\n",
      "2023-11-02 09:39:14.094393: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:459] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-11-02 09:39:14.094419: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1746] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2023-11-02 09:39:14.094538: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2023-11-02 09:39:14.098121: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:142] cuptiFinalize: ignored due to a previous error.\n",
      "2023-11-02 09:39:14.098141: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:459] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-11-02 09:39:14.098147: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1837] function cupti_interface_->Finalize()failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "Epoch 1/3\n",
      "  70/1875 [>.............................] - ETA: 4s - loss: 0.9630 - accuracy: 0.6598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 09:39:14.896262: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-11-02 09:39:14.896496: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-11-02 09:39:14.896550: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-11-02 09:39:14.896583: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:186] cuptiSubscribe: ignored due to a previous error.\n",
      "2023-11-02 09:39:14.896609: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:459] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-11-02 09:39:14.896635: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1746] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2023-11-02 09:39:14.905639: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2023-11-02 09:39:14.907421: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:142] cuptiFinalize: ignored due to a previous error.\n",
      "2023-11-02 09:39:14.907497: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:459] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-11-02 09:39:14.907529: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1837] function cupti_interface_->Finalize()failed with error \n",
      "2023-11-02 09:39:14.908876: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-11-02 09:39:14.908953: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-11-02 09:39:14.908988: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_collector.cc:541]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2023-11-02 09:39:14.911297: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2023-11-02 09:39:14.911791: I tensorflow/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: logs/plugins/profile/2023_11_02_09_39_14/c206-1.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5006 - accuracy: 0.8211 - val_loss: 0.4477 - val_accuracy: 0.8327\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3862 - accuracy: 0.8573 - val_loss: 0.3923 - val_accuracy: 0.8597\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3510 - accuracy: 0.8719 - val_loss: 0.3764 - val_accuracy: 0.8646\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "\n",
    "    model = create_model()\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "#  logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\", histogram_freq=1,\n",
    "                                                        profile_batch = 2)\n",
    "\n",
    "#  tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = \"logs\",\n",
    "#                                                 histogram_freq = 1,\n",
    "#                                                 profile_batch = '500,520')\n",
    "    model.fit(x=x_train, \n",
    "            y=y_train, \n",
    "            epochs=3, \n",
    "            validation_data=(x_test, y_test), \n",
    "            callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if not device_name:\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df20696d",
   "metadata": {},
   "source": [
    "    Para visualizar tensorboard tenemos que hacer un doble tunel al ft3 y al nodo de computación asignado usando el puerto donde esté \"escuchando\" tensorboard. \n",
    "\n",
    "    ssh username@ft3.cesga.es -L port:localhost:port ssh cxxx-y port:localhost:port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "105cef11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6005: logdir logs (started 3:04:14 ago; pid 524625)\n",
      "  - port 6007: logdir ./logs (started 2:02:43 ago; pid 526126)\n",
      "  - port 6010: logdir ./logs (started 0:01:58 ago; pid 554587)\n",
      "  - port 6005: logdir ./logs (started 2:56:49 ago; pid 524835)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e129a242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting TensorBoard with logdir ./logs (started 0:01:59 ago; port 6010, pid 554587).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-977a4ecc3a5daa94\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-977a4ecc3a5daa94\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6010;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook.display(port=6010, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad50304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
